

We design a novel, communication-efficient, failure-robust protocol for secure aggregation of high-dimensional data. Our protocol
allows a server to compute the sum of large, user-held data vectors from mobile devices in a secure manner (i.e. without learning
each user’s individual contribution), and can be used, for example,
in a federated learning setting, to aggregate user-provided model
updates for a deep neural network. We prove the security of our
protocol in the honest-but-curious and active adversary settings,
and show that security is maintained even if an arbitrarily chosen
subset of users drop out at any time. We evaluate the efficiency
of our protocol and show, by complexity analysis and a concrete
implementation, that its runtime and communication overhead remain low even on large data sets and client pools. For 16-bit input
values, our protocol offers 1.73x communication expansion for 21°
users and 27°-dimensional vectors, and 1.98x expansion for 214
users and 2?4-dimensional vectors over sending data in the clear.

