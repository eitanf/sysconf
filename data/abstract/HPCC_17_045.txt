
Traditional data centers are designed with a rigid
architecture of fit-for-purpose servers that provision resources
beyond the average workload in order to deal with occasional
peaks of data. Heterogeneous data centers are pushing towards more cost-efficient architectures with better resource
provisioning. In this paper we study the feasibility of using
disaggregated architectures for intensive data applications, in
contrast to the monolithic approach of server-oriented architectures. Particularly, we have tested a proactive network analysis
system in which the workload demands are highly variable.
In the context of the dReDBox disaggregated architecture, the
results show that the overhead caused by using remote memory
resources is significant, between 66% and 80%, but we have
also observed that the memory usage is one order of magnitude
higher for the stress case with respect to average workloads.
Therefore, dimensioning memory for the worst case in conventional systems will result in a notable waste of resources.
Finally, we found that, for the selected use case, parallelism is
limited by memory. Therefore, using a disaggregated architecture will allow for increased parallelism, which, at the same
time, will mitigate the overhead caused by remote memory.

