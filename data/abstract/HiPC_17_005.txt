
In Machine Learning, the parent set identification
problem is to find a set of random variables that best explain
selected variable given the data and some predefined scoring
function. This problem is a critical component to structure
learning of Bayesian networks and Markov blankets discovery,
and thus has many practical applications, ranging from fraud
detection to clinical decision support.

In this paper, we introduce a new distributed memory
approach to the exact parent sets assignment problem. To
achieve scalability, we derive theoretical bounds to constraint
the search space when MDL scoring function is used, and we
reorganize the underlying dynamic programming such that the
computational density is increased and fine-grain synchronization is eliminated. We then design efficient realization of our
approach in the Apache Spark platform. Through experimental
results, we demonstrate that the method maintains strong
scalability on a 500-core standalone Spark cluster, and it can
be used to efficiently process data sets with 70 variables, far
beyond the reach of the currently available solutions.

