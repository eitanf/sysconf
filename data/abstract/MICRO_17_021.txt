

Finite State Automata are widely used to accelerate pattern matching
in many emerging application domains like DNA sequencing and
XML parsing. Conventional CPUs and compute-centric accelerators
are bottlenecked by memory bandwidth and irregular memory access
patterns in automata processing.

We present Cache Automaton, which repurposes last-level cache
for automata processing, and a compiler that automates the process
of mapping large real world Non-Deterministic Finite Automata
(NFAs) to the proposed architecture. Cache Automaton extends a
conventional last-level cache architecture with components to accelerate two phases in NFA processing: state-match and state-transition.
State-matching is made efficient using a sense-amplifier cycling
technique that exploits spatial locality in symbol matches. Statetransition is made efficient using a new compact switch architecture.
By overlapping these two phases for adjacent symbols we realize an
efficient pipelined design.

We evaluate two designs, one optimized for performance and the
other optimized for space, across a set of 20 diverse benchmarks.
The performance optimized design provides a speedup of 15 over
DRAM-based Micronâ€™s Automata Processor and 3840 speedup
over processing in a conventional x86 CPU. The proposed design
utilizes on an average 1.2MB of cache space across benchmarks,
while consuming 2.3nJ of energy per input symbol. Our space optimized design can reduce the cache utilization to 0.72MB, while still
providing a speedup of 9x over AP.

