
We focus on data fusion, i.e., the problem of unifying conflicting
data from data sources into a single representation by estimating
the source accuracies. We propose SLiMFast, a framework that expresses data fusion as a statistical learning problem over discriminative probabilistic models, which in many cases correspond to logistic regression. In contrast to previous approaches that use complex generative models, discriminative models make fewer distributional assumptions over data sources and allow us to obtain rigorous theoretical guarantees. Furthermore, we show how SLiMFast
enables incorporating domain knowledge into data fusion, yielding
accuracy improvements of up to 50% over state-of-the-art baselines. Building upon our theoretical results, we design an optimizer
that obviates the need for users to manually select an algorithm
for learning SLiMFastâ€™s parameters. We validate our optimizer on
multiple real-world datasets and show that it can accurately predict
the learning algorithm that yields the best data fusion results.
