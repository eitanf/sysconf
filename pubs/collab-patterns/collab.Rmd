---
title: Gender differences in collaboration patterns in computer science
bibliography: ../sysconf.bib
simplesummary: |
  A Simple summary goes here.
abstract: |
  A single paragraph of about 200 words maximum. For research articles,
  abstracts should give a pertinent overview of the work. We strongly encourage
  authors to use the following style of structured abstracts, but without
  headings: 1) Background: Place the question addressed in a broad context and
  highlight the purpose of the study; 2) Methods: Describe briefly the main
  methods or treatments applied; 3) Results: Summarize the article's main
  findings; and 4) Conclusion: Indicate the main conclusions or interpretations.
  The abstract should be an objective representation of the article, it must not
  contain results which are not presented and substantiated in the main text and
  should not exaggerate the main conclusions.
keywords: |
  keyword 1; keyword 2; keyword 3 (list three to ten pertinent keywords specific
  to the article, yet reasonably common within the subject discipline.).
acknowledgement: |
  All sources of funding of the study should be disclosed. Please clearly
  indicate grants that you have received in support of your research work.
  Clearly state if you received funds for covering the costs to publish in open
  access.
authorcontributions: |
  For research articles with several authors, a short paragraph specifying their
  individual contributions must be provided. The following statements should be
  used ``X.X. and Y.Y. conceive and designed the experiments; X.X. performed the
  experiments; X.X. and Y.Y. analyzed the data; W.W. contributed
  reagents/materials/analysis tools; Y.Y. wrote the paper.'' Authorship must be
  limited to those who have contributed substantially to the work reported.
conflictsofinterest: |
  The authors declare no conflict of interest.
funding: |
  Funding for this work was generously provided by the Reed College Social Justice Research and Education Fund.
institutionalreview: |
  This study was exempted from the informed consent requirement under Exempt Category 4: the use of secondary data by Reed College's Institutional Review Board (No. 2021-S26).
informedconsent: |
  The data collected for this study was sourced from public-use datasets such as conference and academic web pages. The informed consent requirement was waived for this secondary analysis.
dataavailability: |
  All of the code and data for this article are publicly available at \url{https://github.com/eitanf/sysconf} \cite{frachtenberg:github-repo}
output:
  bookdown::pdf_book:
    keep_tex: true
    template: main.tex
    citation_package: natbib
    fig_caption: true
---

```{r code = readLines("../load_data.R"), echo = F, message = F}
```

```{r setup, echo=F, message=F, warning=F, cache=T}
library('rjson')
library('kableExtra')

# Colors:
cwomen <- "#7704FF"
cmen <- "#00C3AA"
cmen <- "gray70"
cwomen <- "gray30"


# This function reads in a .json conference file and for each paper in the conference it extracts the author names, paper id,
# field, and conference id into a data frame. It then normalizes the names using 'normalized_author_name' and moves
# on to the next paper, stacking the new data frame with those that have already been created each time.
# Finally it normalizes the author names and joins with a gender mapping df to get the corresponding genders.

json_to_df <- function(conf_name, gender_mapping) {
  json_fpath <- paste0(toplevel, "data/conf/", conf_name, ".json")
  conf <- rjson::fromJSON(file = json_fpath)
  confname <- conf[[1]]
  field <- conf[['field']]
  subfield <- conf[['subfield']]
  papers <- conf[['papers']]
  submissions <- conf[['submissions']]

  conf_info_df <- data.frame()

  for (i in seq_along(papers)) {
    paper_id <- unlist(papers[[i]][1])
    authors <- as.data.frame(papers[[i]][3]) %>%
      mutate(conf = confname,
             field = field,
             subfield = subfield,
             paper_id = paper_id,
             n_submissions = submissions)

    conf_info_df <- bind_rows(conf_info_df, authors)
  }

  conf_info_df <- conf_info_df %>%
    mutate(authors = map_chr(authors, normalized_author_name)) %>%
    mutate(authors = str_replace(authors, "\\s+", " ")) %>%
    mutate(paper_id = as.factor(paper_id)) %>%
    rename(name = authors)

  conf_info_df %>%
    left_join(gender_mapping, by = "name")
}

######################
# Here we create a vector of the conference names and use the 'map_dfr' function to apply 'json_to_df' to each conference.
nonsys_confs <-
  c("AAAI", "ACL", "CHI", "CVPR", "FSE", "ICML", "ICSE", "MM", "NIPS", "POPL", "SIGCSE", "SIGGRAPH", "SODA", "STOC", "WSDM", "WWW", "ITICSE", "FOCS", "TACAS")

nonsys_authors <- nonsys_confs %>%
  map_dfr(~json_to_df(.x, all_genders)) %>%
  mutate(across(.cols = everything(), na_if, "NA")) %>%
  mutate(across(c(field, subfield, gender), factor))
  

###########
name_combination_creator <- function(df)
{
  authors <- df$name
  if (length(authors) <= 1) {
    return (data.frame(name1 = c(), name2 = c()))
  }

  ret <- as.data.frame(t(combn(authors, 2)))
  names(ret) <- c("name1", "name2")
  ret <- rbind(ret, data.frame(name1 = ret$name2, name2 = ret$name1))
  return(ret)
}

#######
# All-to-all coauthor pairs for non-sys and for sys:
nonsys_collaboration_pairs <- nonsys_authors %>%
  group_by(paper_id) %>%
  group_modify(~name_combination_creator(.x)) %>%
  ungroup() %>%
  left_join(all_genders, by = c("name2" = "name")) %>%
  rename(gender2 = gender) %>%
  left_join(all_genders, by = c("name1" = "name")) %>%
  rename(gender1 = gender) %>%
  dplyr::select(paper_id, name1, gender1, name2, gender2)

sys_collaboration_pairs <- coauthors %>%
  left_join(persons, by = c("name1" = "name", "gs_email1" = "gs_email")) %>%
  rename(gender1 = gender, paper_id = paper) %>%
  left_join(persons, by = c("name2" = "name", "gs_email2" = "gs_email")) %>%
  rename(gender2 = gender) %>%
  dplyr::select(paper_id, name1, gender1, name2, gender2) %>%
  distinct(name1, name2, paper_id, .keep_all = T)

all_pairs <- rbind(nonsys_collaboration_pairs, sys_collaboration_pairs)

#####################
gender_summary_table <- function(data)
{
  data %>%
    summarise(.groups = "keep",
      n_papers = n_distinct(paper_id, conf),
      n_na = sum(is.na(gender)),
      n_male = sum(gender == "M", na.rm = T),
      n_female = sum(gender == "F", na.rm = T),
      prop_female = n_female / (n_female + n_male)
    ) %>%
    arrange(desc(prop_female)) %>%
    knitr::kable()
}

#######

sys_auths <- roles %>%
  filter(role == "author") %>%
  left_join(persons, by = c("name" = "name", "gs_email" = "gs_email")) %>%
  dplyr::select(name, gender, key, gs_email) %>%
  mutate(conf = as.factor(gsub("_\\d\\d\\d$", "", key))) %>%
  left_join(all_confs, by = c("conf" = "conference")) %>%
  rename(key = key.x) %>%
  dplyr::select(name, gender, key, field, subfield)

nonsys_auths <- nonsys_authors %>%
  dplyr::select(-conf, -n_submissions) %>%
  dplyr::select(name, gender, paper_id, field, subfield) %>%
  rename(key = paper_id) %>%
  mutate(gs_email = NA)

full_auths <- bind_rows(sys_auths, nonsys_auths) %>%
  group_by(key) %>%
  mutate(coauthors = n() - 1)

full_auths <- full_auths %>%
  group_by(name, gender) %>%
  mutate(prod = n(), fractional_prod = sum(1 / (coauthors + 1)))

full_auths$subfield = recode_factor(full_auths$subfield,
                                    "Heterogeneous Computing" = "Computer Architecture",
                                    "Network" = "Communications",
                                    "Virtualization" = "Operating Systems",
                                    "Energy" = "Computer Architecture",
                                    "Architecture" = "Computer Architecture")

full_auths$field = recode_factor(full_auths$field,
                                 "Systems" = "Computer Systems",
                                 "Computer Science Education" = "CS Education",
                                 "Artificial Intelligence" = "AI",
                                 "Human-Computer Interaction" = "HCI",
                                 "Theory and Algorithms" = "Theory",
                                 "Software Engineering & Languages" = "SE/languages")

gen_auths <- full_auths %>% drop_na(gender)

########
pairs_with_field <- full_auths %>%    # Add field and subfield to all_pairs
  mutate(paper_id = key) %>%
  group_by(paper_id) %>%
  summarize(.groups = "keep", field = first(field), subfield = first(subfield)) %>%
  right_join(all_pairs) %>%
  ungroup() %>%
  drop_na(gender1) %>%
  drop_na(gender2) %>%
  group_by(subfield) %>%
  mutate(internal = sum(gender1 == gender2), external = sum(gender1 != gender2)) %>%
  mutate(ei_index = (external - internal) / (external + internal)) %>%
  mutate(w_prob = sum(gender1 == "F" & gender2 == "F") / sum(gender1 == "F"))
  
#######
productivity_diff <- function(sf)
{
  men <- filter(gen_auths, gender == "M", subfield == sf)
  women <- filter(gen_auths, gender == "F", subfield == sf)
  paste0(round(mean(men$prod) - mean(women$prod), 2), "; ",
         report_test(t.test(men$prod, women$prod)))
}

#### Summary table of properties of subfields.
tmp <- pairs_with_field %>%
  group_by(subfield, field) %>%
  summarize(.groups = "keep", ei_index = first(ei_index), wprob = first(w_prob))

subfield_summary <- gen_auths %>%
  group_by(subfield) %>%
  summarize(.groups = "keep",
            FAR = sum(gender == "F") / n(),
            avg_prod = mean(prod),
            avg_frac = mean(fractional_prod),
            avg_coauthors = mean(coauthors)) %>%
  ungroup() %>%
  left_join(tmp) %>%
  mutate(whomo = wprob / FAR)
```

# Introduction

The gender gap in science, technology, engineering and mathematics (STEM), and in particular in computer science (CS), is a well-known and well-studied problem.
It carries significant societal effects, such as inequality in economic opportunities for women and an undersupply of researchers and engineers in the rapidly growing discipline [@nielsen17:opinion; @mattis07:upstream].
The gender gap among researchers is particularly severe: the people who participate in research, publish about it, and have their research acknowledged for its value are predominantly men [@charman17:championing].
Numerous studies estimate that only about 15%--30% of the CS research community are women [@cohoon11:cspapers; @holman18:gender; @national20:science; @way16:gender; @zweben18:taulbee].
Although some recent indications show these numbers could be growing, they remain low, and the rate of growth remains slow [@wang21:trends].

The gender gap is a complex, multifaceted challenge [@avolio20:factors].
Numerous approaches to understand and perhaps address the gender gap have focused on aspects such as resource availability, gender stereotypes, child care, structural barriers, gender differences, discrimination, and other factors.
This article focuses on one of these factors: the collaboration patterns of paper coauthors across genders and CS fields.

Scientific collaborations are the backbone of a successful career in science [@whittington18:tie].
For example, researchers with more collaborators have been found to publish more articles, in higher impact journals, and accrue more citations more quickly [@lee05:impact].
Consequently, many studies investigated whether women and men collaborate at different rates across disciplines, and often found significant differences [@bozeman04:scientists; @hunter08:collaborative; @kyvik96:child; @scott90:disadvantage].

In CS, and in particular in its more experimental fields such as computer systems, graphics, and artificial intelligence, collaboration is crucial because the large-scale implementation efforts involved often require teams of researchers with various experience levels.
In this article we focus on gender differences in collaboration patterns across the fields and subfields of CS.

Our study design is descriptive and observational in nature.
We did not start out with any preset hypotheses to validate.
Instead, our goal was to collect and analyze up-to-date, accurate and extensive data on CS authorship and collaboration patterns across genders.
This data and analysis provides baseline statistics for comparison across different time points and scientific disciplines.
But it also provides immediate answers and comparisons to other works that can provide new insights into the current state of collaboration differences across genders and CS fields.
Specifically, in this article we address the following research questions:

 *  **RQ1**: What are the ratios of women and men among CS conference authors?
 
 *  **RQ2**: Do women publish less than men?

 *  **RQ3**: Are productivity differences affected by collaboration size?

 *  **RQ4**: Do women collaborate with fewer people than men?

 *  **RQ5**: Do women publish fewer single-author papers?

 *  **RQ6**: Are team sizes (coauthor groups) larger in more experimental subfields?

 *  **RQ7**: Do authors exhibit gender homophily in their choice of coauthors?

To bring these questions into historical context, we next briefly survey some of the previous work in the area.

## Related work {-}

There exists rich literature on the gender gap in sciences in general, and in computer science research in particular.
For a recent review of these works, refer to [@avolio20:factors].
Instead, we limit our focus to the relevant literature on collaboration patterns and differences.

For example, a recent study of differences in collaboration patterns across disciplines found that female scientists have a lower probability of repeating previous coauthors than males.
It also found that female faculty have significantly fewer distinct coauthors over their careers than males, but that this difference can be fully accounted for by females’ lower publication rate and shorter career lengths [@zeng16:differences].

This productivity gap, which we observed in our dataset as well, has been thoroughly explored in a different study [@symonds06:gender].
In the social sciences, one study has found that women generally publish fewer papers than men, and that two thirds of the single-author papers were written by men [@schucan11:women].
In mathematics, women also publish less than men, especially early in their careers, and leave academia at a higher rate then men [@mihaljevic16:effect].
Women are also underrepresented in the three top-ranked journals and publish fewer single-author papers. In terms of mean number of coauthors, women's statistics are similar to men's.
There is even a gap in recognition, as women are also less likely to receive tenure the more they coauthor [@sarsons17:recognition].


CS researchers in particular tend to collaborate more than researchers in other fields, regardless of gender, and there are no gender-specific differences in how collaborative behavior impacts scientific success [@jadidi18:gender].
This study also found that gender homophily in CS has been increasing over the past few years.

Related, another study of collaboration patterns across sciences found that CS papers average 2.84 coauthors, and electrical engineering papers average 3.04 [@ghiasi15:compliance], similar to what we have found in this study.
It also found that generally in engineering, female-female collaborations accounted for only 7% of all total pairs.
In CS, the percentage is even lower (5%).
Since 1990, there have been even more same-gender (gender homophily) coauthorships than expected [@wang21:trends].
But this property can vary across CS fields, necessitating more nuanced analysis.
For example, in the field of data visualization, women collaborated with substantially more women than men [@tovanich21:gender].

Corroborating this result for biotech patent networks, women have been found more likely to collaborate with women, and benefit from it, but both genders collaborate with mostly men [@whittington18:tie].
There are also fewer women "stars", which we also found to hold specifically for the subfield of high-performance computing [@frachtenberg21:whpc].

A surprising result came from a survey of 1,714 scientists in 2011, finding that when accounting for various confounding factors, women actually have more collaborators then men [@bozeman11:men].
The paper also reported that regression models that take into account different collaboration strategies are better at predicting a researcher's number of collaborators.

Several studies analyzed the gender gap by aggregating the coauthors of each paper into one "gender".
One study analyzed different aggregations based the proportion of female authors, gender of most senior authors, and single-author papers [@hengel17:publishing].
Looking at author position for aggregation, another study found that there are fewer women in first and last author positions in science overall, as well as in single-author papers [@west13:role].
Other ways to aggregate genders including counting all papers that have at least one female author, and those where at least half the authors are female.


## Organization {-}

The rest of this paper is organized as follows.
In the next section (Sec. \@ref(sec:data)), we describe in detail our data collection methodology, including the manual assignment of genders to authors to avoid the well-known issues of name-based gender inference.
In the results section (Sec. \@ref(sec:results)), we enumerate our findings, organized by research question, and then summarize an answer to each of the questions.
The discussion (Sec. \@ref(sec:discussion)) that follows then elaborates on these answers in an attempt to synthesize insights.
Finally, we conclude in Sec. \@ref(sec:conclusion) and suggest directions for future research.

<!-------------------------------------------------------------------------------->
<!-------------------------------------------------------------------------------->

# Materials and Methods {#sec:data}

To answer our research questions, we needed to collect expansive data on CS publications and their authors.
Such data collection involves many choices, such as which publications to collect and how to assign gender to authors.
The following list enumerates our main data decisions.
Each choice necessarily involves trade-offs, and we attempt to justify our choices by explaining which aspects we prioritized.

```{r all-confs, echo=F, cache=T}
# this is all nonsys conferences
nonsys_full_table <- nonsys_authors %>%
  group_by(conf) %>%
  mutate(Papers = n_distinct(paper_id, conf), Authors = n_distinct(name, conf, na.rm = T)) %>%
  distinct(conf, .keep_all = T) %>%
  ungroup() %>%
  mutate(Acceptance = round(Papers / n_submissions, 2)) %>%
  mutate(Conference = gsub("_\\d*", "", conf)) %>%
  dplyr::select(Conference, subfield, field, Papers, Authors, Acceptance) %>%
  rename(Field = field, Subfield = subfield)

# this is all other conferences
sys_full_table <- all_confs %>%
  mutate(Conference = gsub("_\\d*", "", conference)) %>%
  rename(Papers = npapers, Authors = authors_num, Field = field, Subfield = subfield) %>%
  mutate(Acceptance = round(acceptance_rate, 2)) %>%
  dplyr::select(Conference, Subfield, Field, Papers, Authors, Acceptance)

full_table <- dplyr::bind_rows(nonsys_full_table, sys_full_table) %>%
  arrange(Subfield, Acceptance)

full_table %>%
  dplyr::select(-c(Field)) %>%
  mutate(Acceptance = ifelse(is.na(Acceptance), "Unknown", Acceptance)) %>%
  knitr::kable(format = "latex",
               booktabs = T,
               align = "llrrr",
               linesep = "",
               caption = "All conferences, ordered by subfield and acceptance rate") %>%
  kable_styling(latex_options = c("hold_position"), font_size = 7)
```

**Conference data instead of journal data.**
In CS, original scientific results are typically first published in peer-reviewed conferences [@patterson99:evaluating; @patterson04:health], and then possibly in archival journals, sometimes years later [@vrettas15:conferences]. To increase the coverage and relevance of our dataset, we only looked at conference publications. The complete list of selected conference can be found in Table \@ref(tab:all-confs).

**Choice of conferences.**
Our dataset evolved from our previous study of conferences related to one major subfield, computer systems [@frachtenberg20:survey].
The conferences we selected include some of the most prestigious systems conferences (based on indirect measurements such as Google Scholar's metrics), as well as several smaller or less-competitive conferences for contrast.
For this specific study, we decided to expand the analysis to include some of the most influential conferences in most subfields of CS, based on the same measures, for a total of `r n_distinct(full_auths$key)` papers across CS.
Obviously, not all subfields have equal numbers of participants or conferences, and we had no set quota for either to be included in our dataset.
Instead, we tried to ensure that each subfield is represented by at least a few hundred authors for statistical power.
* Limit data to a single year.
Many fields and researchers shift characteristics over time, complicating collaboration analyses.
To control for these effects, all of the conferences in our dataset are from a single year, 2017.

**Focus on manual gender assignment.**
Most studies of author gender at scale use automated approaches to assign gender to authors, typically inferred from given names [@huang20:historical; @karimi16:gender].
These statistical approaches can be reasonably accurate for names of Western origin, and especially for male names  [@cohoon11:cspapers; @mattauch20:bibliometric; @santamaria18:comparison].
We opted instead to rely primarily on a manual approach that can overcome the limitations of name-based inference.
Using web lookup, we assigned the gender of
`r fmt(nrow(verified_gender) + nrow(verified_gender_nonsys))`
of the unique researchers for whom we could identify an unambiguous web page with a recognizable gendered pronoun or absent that, a photo.
(For example, many Linkedin profiles may lack a photo, but include a gendered pronoun in the recommendations section.)
For `r fmt(nrow(inferred_gender) + nrow(inferred_gender_nonsys))`
others, we used genderize.io's automated gender designations if it was at least 90% confident about them [@santamaria18:comparison].
The remaining
`r fmt(filter(full_auths, is.na(gender)) %>% pull(name) %>% unique() %>% length())`
persons were assigned "NA" instead of a gender and were excluded from most analyses.
This method provided more gender data and higher accuracy than automated approaches based on forename and country, especially for women [@karimi16:gender; @lariviere13:bibliometrics; @mattauch20:bibliometric; @squazzoni20:noevidence; @wang21:trends].
Consequently, we have very few NA genders because of our manual approach, relative to comparable studies.
We believe that when analyzing coauthorship networks in particular, omitting a large number of connected sub-networks (such as people from Asia) may distort our results.

**Assignment of field and subfield.**
We could find no comprehensive definition and delineation of fields and subfields of CS, so we had to come up with our own, which is necessarily subjective (Table \@ref(tab:subfield-mapping)).
Moreover, conferences do not always fall neatly into a single subfield, and some papers may stray from the primary focus of the conference.
We note, however, that in most of our analyses, papers subfields assigned to the same field often exhibited similar characteristics to each other and distinct from other subfields.
This affinity provides evidence that these assignments are not entirely arbitrary.
That said, other researchers may therefore choose different assignments of papers or conferences to subfields and fields.
Since our dataset and code are both open and available, we welcome such reevaluations of the data.

```{r subfield-mapping, echo=F, cache=T}
df <- full_auths %>%
  group_by(subfield) %>%
  summarize(.groups = "keep", Field = first(field)) %>%
  rename(Subfield = subfield)

df$Field = recode_factor(df$Field,
                         "AI" = "Artificial Intelligence (AI)",
                         "HCI" = "Human-Computer Interaction (HCI)",
                         "SE/languages" = "Software Engineering & Programming Languages")

df %>%
  arrange(Field, Subfield) %>%
  knitr::kable(format = "latex",
               booktabs = T,
               align = "ll",
               linesep = "",
               caption = "All CS subfields analyzed, arranged by fields") %>%
  kable_styling(font_size = 7)
```


## Limitations {-}

The choices listed above also represent some compromises that limit the generalization or applicability of our analysis.
One such limitation is that the data reflects a snapshot in time to avoid the complexities of gender differences in retention rates.
However, this choice precludes analyses of changes and trends in collaboration patterns over time.

Another limitation is our which conferences to include out of the hundreds or thousands of annual CS conferences.
Our conference choices may not be not representative of all of CS or even a proportional representation of subfields with CS.
The relative metrics we measured comparing different subfields are nevertheless meaningful, but overall metrics should be taken with a grain of salt.
We hope that the large number of authors we included in our dataset does not significantly deviate from a representative sample of the field of CS as a whole.

For this study, the most critical piece of information on these researchers is their \emph{perceived gender}.
Gender is a complex, multifaceted identity, but most bibliometric studies still rely on binary genders---either collected by the journal, or inferred from first name---because that is the only designator available to them [@bhagat18:data; @cohoon11:cspapers; @holman18:gender; @national20:science; @wang21:trends; @way16:gender; @zweben18:taulbee].
In the absence of self-identified gender information for our authors, we also necessarily compromised on using binary gender designations.
We therefore use the gender terms "women" and "men" interchangeably with the sex terms "female" and "male".
The conferences in our dataset did not collect or share specific gender information, so we had to collect this information from other public sources.

This labor-intensive approach does introduce the prospect of human bias and error.
For example, a gender assigned by an outdated biography paragraph with pronouns may no longer agree with the self-identification of the researcher.
To verify the validity of our approach, we compared our manually assigned genders to self-assigned binary genders in a separate survey we conducted among 918 of the authors  [@frachtenberg20:survey].
We found no disagreements for these authors, which suggests that the likelihood of disagreements among the remaining authors is low.
But the main limitation that arises from this manual process of data collection and gender assignment, is that it does not scale well to many more conferences or years.

Finally, the nature of the current analysis is more descriptive than prescriptive.
Rather than presenting preconceived hypotheses and testing them with the data, we ask and answer open-ended research questions.
In particular, the scope of this study excludes social network analysis, which is also important to understanding collaboration patterns [@whittington18:tie] and we hope to address in followup work.
The open dataset we provide with this article should enable any interested researcher to perform such analyses.

## Statistics {-}

For statistical testing, group means were compared pairwise using Welch's two-sample t-test and group medians using the Wilcoxon Signed Rank Test; differences between distributions of two categorical variables were tested with the $\chi^{2}$ test; and correlations between two numerical variables were evaluated with Pearson's product moment correlation coefficient.
All statistical tests are reported with their p-values.


<!-------------------------------------------------------------------------------->
<!-------------------------------------------------------------------------------->

# Results {#sec:results}

For each research question, we start with descriptive statistics across the entire sample population, and then break the statistics down by field and subfield.

## RQ1 What are the ratios of women and men among CS conference authors?

Before we can look at collaboration patterns, we need to establish a baseline for authorship numbers across genders.
For example, the question of how many women or men an author collaborates with makes little sense without the context of how many women and men are available to collaborate with overall.
The first question we ask, therefore, is what is the female author ratio (FAR) in our dataset.

Summarizing across all `r fmt(nrow(full_auths))` authors (with repeats for multiple papers) and omitting the `r fmt(sum(is.na(full_auths$gender)))` authorships for which we could establish no gender, we find a total of `r fmt(sum(gen_auths$gender == "F"))` women, which represents an overall FAR of
`r pct(sum(gen_auths$gender == "F"), nrow(gen_auths))`% across authors (with repeated counts for multiple publications).
This result is on the low end of previously reported statistics in the range of 15--30% [@cohoon11:cspapers; @holman18:gender; @national20:science; @way16:gender; @zweben18:taulbee].
Keep in mind, however, the differences between those studies and this one, both in data and in methodology.
Our data is modest in size when compared to some other studies, and includes only conferences and only from one year.
Our selection of conferences is by no means exhaustive or objective, and is likely to be overweight in some areas of CS and underweight in others.
However, the smaller sample size allowed us to apply a primarily manual approach to gender assignment, which provides higher accuracy and coverage of researchers.
In contrast, most comparable studies use a gender inference approach based on given names, which can fail for names with unclear or no gender association at all, as are many East Asian names, and tend to misidentify women in particular [@cohoon11:cspapers; @mattauch20:bibliometric; @santamaria18:comparison].
We believe these two differences can explain much of the gap between the FARs observed in our data and in previous datasets.

```{r FAR-by-subfield, echo=F, warning=F, message=F, cache=T, out.width='0.75\\textwidth', fig.cap="Female author ratio by subfield"}
gen_auths %>%
  group_by(subfield) %>%
  summarize(.groups = "keep", FAR = sum(gender == "F") / n(), N = n(), field = first(field), subfield = first(subfield)) %>%
  ggplot(aes(x = fct_reorder(subfield, FAR), y = FAR, fill = field)) +
    geom_bar(stat = "identity") +
    geom_text(aes(x = fct_reorder(subfield, FAR), y = 0.42, label = paste0(subfield, "  N=", fmt(N))), hjust = 1, angle = 0, size = 3) +
    scale_y_continuous(labels = scales::percent) +
    xlab("Subfield") +
    ylab("Female author ratio") +
    labs(fill = "") +
    coord_flip() +
    scale_fill_brewer(palette = "Paired") +
    theme_minimal() +
    theme(legend.position = "bottom",
#          legend.justification = c(0, 0),
          axis.text.y = element_blank(),
          #element_text(angle = 90, hjust = 1, vjust = -0.00001),
          legend.box = "vertical",
          legend.margin = margin())
```

Looking at FAR for each field and subfield (Fig. \@ref(fig:FAR-by-subfield)), we find large differences across CS.
The highest FAR was exhibited in CS education conferences
(`r pct(nrow(filter(gen_auths, gender == "F", subfield == "Computer Science Education")), nrow(filter(gen_auths, subfield == "Computer Science Education")))`%)
and the lowest in theoretical CS
(`r pct(nrow(filter(gen_auths, gender == "F", subfield == "Theoretical Computer Science")), nrow(filter(gen_auths, subfield == "Theoretical Computer Science")))`%).
Most conferences in the field of computer systems hovered around 10% FAR while the entire field of AI averaged a little huger at
(`r pct(nrow(filter(gen_auths, gender == "F", field == "AI")), nrow(filter(gen_auths, field == "AI")))`%).



---

## RQ2: Do women publish less than men?

Many papers across disciplines discuss the existence and potential reasons for a productivity gap, that is, the observation that men generally publish more scholarly articles than women.
Here, we continue our exploration of the data by looking at the productivity rates across genders and subfields of CS.


```{r productivity-dist, echo=F, warning=F, message=F, cache=T, out.width='0.75\\textwidth', fig.cap="Distribution of number of distinct papers per author"}
gen_auths %>%
  ggplot(aes(x = prod, fill = gender)) +
    geom_histogram(position = "dodge", binwidth = 1) +
    scale_fill_manual(values = c(cwomen, cmen), labels = c("Women", "Men")) +
    theme_classic() +
    theme(legend.position = "bottom") +
    xlab("Papers in dataset") +
    ylab("Total authors")
```

Fig. \@ref(fig:productivity-dist) shows the overall distributions of paper productivity in CS across genders.
Aside from the now-obvious observation that men far outnumber women authors, we can also observe a longer tail for the men's distribution overall.
The interpretation is that the most prolific authors are especially skewed male.
On the opposite tail, we find that
`r pct(nrow(filter(gen_auths, gender == "F", prod == 1)), nrow(filter(gen_auths, gender == "F")))`%
of female authors published only one paper in our dataset, compared to
`r pct(nrow(filter(gen_auths, gender == "M", prod == 1)), nrow(filter(gen_auths, gender == "M")))`%
of men.

Overall, men average
`r round(mean(filter(gen_auths, gender == "M")$prod), 2)`
papers per author, compared to women's
`r round(mean(filter(gen_auths, gender == "F")$prod), 2)`
(`r report_test(t.test(filter(gen_auths, gender == "F")$prod, filter(gen_auths, gender == "M")$prod))`).
Looking at medians---to attempt to attenuate the large effect of the long tail on means---does not help much.
Both medians are naturally 1; but a Wilcoxon signed rank test still shows a significant difference
(`r report_test(wilcox.test(filter(gen_auths, gender == "F")$prod, filter(gen_auths, gender == "M")$prod))`).


```{r productivity-by-subfield, echo=F, warning=F, message=F, cache=T, fig.height=6.5, out.width='0.75\\textwidth', fig.cap="Distribution of number of distinct papers per author by gender, field, and subfield. Triangles denote means and veritcal notches denote medians. Dots denote outlier points outside the 5--95\\% range."}
gen_auths %>%
  group_by(subfield) %>%
  mutate(avg_prod = mean(prod), N = n()) %>%
  ungroup() %>%
  ggplot(aes(x = fct_reorder(subfield, avg_prod), y = prod, fill = gender, color = field)) +
    geom_boxplot(lwd = 0.5) +
    geom_point(aes(y = avg_prod), color = "black", shape = 2) +
#    geom_text(aes(x = fct_reorder(subfield, avg_prod), y = 21, label = paste0("N=", N)), hjust = 1.1) +
    xlab("Subfield") +
    ylab("Paper count per author") +
    theme_classic() +
    theme(legend.position = "bottom", legend.box = "vertical") +
    guides(fill = guide_legend(direction = 'horizontal', title = "Gender"),
           color = guide_legend(direction = 'horizontal', title = "Field")) +
    scale_fill_manual(values = c(cwomen, cmen), labels = c("Women", "Men")) +
    scale_color_brewer(palette = "Paired") +
    coord_flip()
```


Fig. \@ref(fig:productivity-by-subfield) shows the breakdown of productivity distribution by gender, field, and subfield.
The field of AI and its subfields show the highest average productivity (and highest outliers, for men), while software engineering, programming languages, and CS education exhibit the lowest average papers per author.
In terms of gender, the largest differences in productivity exhibit in the subfield of theoretical CS (difference in means $\Delta$=`r productivity_diff("Theoretical Computer Science")`), followed by machine learning ($\Delta$=`r productivity_diff("Machine Learning")`), benchmarking ($\Delta$=`r productivity_diff("Benchmarking")`), HPC ($\Delta$=`r productivity_diff("High-Performance Computing")`), AI ($\Delta$=`r productivity_diff("Artificial Intelligence")`), and security ($\Delta$=`r productivity_diff("Security")`).
A few subfields show a small productivity advantage for women, such as programming languages ($\Delta$=`r productivity_diff("Programming Languages")`), but none are statistically significant.

---

## RQ3: Are productivity differences affected by collaboration size?


Comparing raw productivity across subfields this way could be misleading, because the typical collaboration size is also related to productivity, but varies by subfield.
If in some subfield, for example the typical number of authors per papers is larger than another field, we might also expect that each author's name would show up in more papers under otherwise equal assumptions.
We therefore also look at the "fractional count" of publication instead, dividing each authorship event by the number of authors on the paper [@lee05:impact].

Overall, men average a total of
`r round(mean(filter(gen_auths, gender == "M")$fractional_prod), 2)`
fractional papers per author, compared to women's
`r round(mean(filter(gen_auths, gender == "F")$fractional_prod), 2)`,
which is statistically significant.
(`r report_test(t.test(filter(gen_auths, gender == "F")$fractional_prod, filter(gen_auths, gender == "M")$fractional_prod))`).


```{r fractional-productivity, echo=F, warning=F, message=F, cache=T, fig.height=6.5, out.width='0.75\\textwidth', fig.cap="Distribution of fractional paper counts per author by gender, field, and subfield. Triangles denote means and veritcal notches denote medians. Dots denote outlier points outside the 5--95\\% range."}
gen_auths %>%
  group_by(subfield) %>%
  mutate(avg_prod = mean(fractional_prod), N = n()) %>%
  ungroup() %>%
  ggplot(aes(x = fct_reorder(subfield, avg_prod), y = fractional_prod, fill = gender, color = field)) +
    geom_boxplot(lwd = 0.5) +
    geom_point(aes(y = avg_prod), color = "black", shape = 2) +
#    geom_text(aes(x = fct_reorder(subfield, avg_prod), y = 21, label = paste0("N=", N)), hjust = 1.1) +
    xlab("Subfield") +
    ylab("Fractional paper count per author") +
    theme_classic() +
    theme(legend.position = "bottom", legend.box = "vertical") +
    guides(fill = guide_legend(direction = 'horizontal', title = "Gender"),
           color = guide_legend(direction = 'horizontal', title = "Field")) +
    scale_fill_manual(values = c(cwomen, cmen), labels = c("Women", "Men")) +
    scale_color_brewer(palette = "Paired") +
    coord_flip()
```

This normalized productivity metric exhibits on the one hand smaller differences across fields, but on the other, larger differences across genders (Fig. \@ref(fig:fractional-productivity)).
Both the medians and the means for men's fractional productivity are noticeably higher in most subfields, and men exhibit much larger and more numerous outliers on the prolific tail of the spectrum.
The ordering of the fields is also somewhat different, with theoretical computer science now exhibiting the highest mean fractional productivity.

The modified productivity metric also segues into the next three research questions that examine in depth the differences in collaboration sizes in CS.


---

## RQ4: Do women collaborate with fewer people than men?

This question could be addressed by two distinct measures: the mean number of coauthors per paper and the size of the total coauthor network for each author.


```{r coauthors-by-subfield, echo=F, warning=F, message=F, cache=T, fig.height=6.5, out.width='0.75\\textwidth', fig.cap="Mean number of coauthors per person by gender and subfield (triangles denote overall mean for subfield)."}
gen_auths %>%
  group_by(subfield) %>%
  mutate(avg_co = mean(coauthors)) %>%
  ungroup() %>%
  group_by(subfield, avg_co, gender) %>%
  summarize(.groups = "keep", Coauthors = mean(coauthors), field = first(field), subfield = first(subfield)) %>%
    ggplot(aes(x = fct_reorder(subfield, avg_co), y = Coauthors, color = gender, fill = field)) +
    geom_bar(stat = "identity", position = "dodge", size = 1) +
    geom_point(aes(y = avg_co), color = "black", shape = 2) +
    xlab("Subfield") +
    ylab("Coauthor count per author") +
    theme_classic() +
    theme(legend.position = "bottom", legend.box = "vertical") +
    guides(color = guide_legend(direction = 'horizontal', title = "Gender"),
           fill = guide_legend(direction = 'horizontal', title = "Field")) +
    scale_color_manual(values = c(cwomen, cmen), labels = c("Women", "Men")) +
    scale_fill_brewer(palette = "Paired") +
    coord_flip()
```

Women in our dataset average
<!--excludes solo authors: `r coauthor_count <- all_pairs %>% group_by(paper_id, name1, gender1) %>% summarize(.groups = "keep", n = n()); round(mean(filter(coauthor_count, gender1 == "F")$n), 2)` -->
`r round(mean(filter(gen_auths, gender == "F")$coauthors), 2)`
coauthors per paper, while men average
`r round(mean(filter(gen_auths, gender == "M")$coauthors), 2)`
(`r report_test(t.test(filter(gen_auths, gender == "F")$coauthors, filter(gen_auths, gender == "M")$coauthors))`).
This metric appears to show no significant differences in the aggregate.
Breaking it down by field (Figure \@ref(fig:coauthors-by-subfield)) shows that the gender differences still remain minimal throughout almost all of CS.
The largest difference appear in the subfields of computer architecture
(`r report_test(t.test(filter(gen_auths, subfield == "Computer Architecture", gender == "F")$coauthors, filter(gen_auths, subfield == "Computer Architecture", gender == "M")$coauthors))`)
and operating systems
(`r report_test(t.test(filter(gen_auths, subfield == "Operating Systems", gender == "F")$coauthors, filter(gen_auths, subfield == "Operating Systems", gender == "M")$coauthors))`).
In general, the field of computer systems stands out with a an average gender gap of
`r round(mean(filter(gen_auths, field == "Computer Systems", gender == "M")$coauthors) -  mean(filter(gen_auths, field == "Computer Systems", gender == "F")$coauthors), 2)`
fewer coauthors for women than for men
(`r report_test(t.test(filter(gen_auths, field == "Computer Systems", gender == "F")$coauthors, filter(gen_auths, field == "Computer Systems", gender == "M")$coauthors))`).


The second measure is how many distinct authors each person collaborates with across all of their papers---in other words, the size of the network of all a person's collaborators.
Again, we observe only a small gender gap, where women average
`r cohorts <- all_pairs %>% group_by(name1, gender1) %>% summarize(.groups = "keep", cohort = n_distinct(name2, gender2)); round(mean(filter(cohorts, gender1 == "F")$cohort), 2)`
total cohort size, while men average
`r round(mean(filter(cohorts, gender1 == "M")$cohort), 2)`
(`r report_test(t.test(filter(cohorts, gender1 == "F")$cohort, filter(cohorts, gender1 == "M")$cohort))`).
This measure also shows no significant gender differences in the aggregate.
Unfortunately, it cannot be neatly broken down by fields, because coauthor networks often include authors that span more than one field.

Overall, men exhibit slightly higher collaboration metrics than women (more coauthors per paper and more coauthors overall), but not significantly so.

---


## RQ5: Do women publish fewer single-author papers?

Next, we turn our attention to single-author papers (Table \@ref(tab:single-authors)).
In our dataset, there is a total of
`r nrow(filter(full_auths, coauthors == 0))`
such papers, of which
`r nrow(filter(full_auths, coauthors == 0, gender == "F"))`
were written by a woman,
`r nrow(filter(full_auths, coauthors == 0, gender == "M"))`
by a man, and the rest unknown.
The ratio of women among single authors with known gender is
`r pct(nrow(filter(gen_auths, coauthors == 0, gender == "F")), nrow(filter(gen_auths, coauthors == 0)))`%,
which is significantly lower than that of the overall
`r pct(nrow(filter(gen_auths, gender == "F")), nrow(filter(gen_auths)))`% FAR
(`r report_test(chisq.test(table(gen_auths$gender == "F", gen_auths$coauthors == 0)))`).

```{r single-authors, eval=T, echo=F, warning=F, message=F, cache=T}
tbl <- full_auths %>%
  group_by(subfield) %>%
  summarize(.groups = "keep",
    Papers = n_distinct(key),
    ratio = sum(coauthors == 0) / n_distinct(key),
    single = sum(coauthors == 0),
    Women = sum(coauthors == 0 & gender == "F", na.rm = T),
    Men = sum(coauthors == 0 & gender == "M", na.rm = T),
    Unknown = sum(coauthors == 0 & is.na(gender), na.rm = T)
  ) %>%
  arrange(desc(ratio))

tbl <- bind_rows(tbl, data.frame(
    subfield = "Total",
    Papers = sum(tbl$Papers),
    ratio = nrow(filter(full_auths, coauthors == 0)) / sum(tbl$Papers),
    single = nrow(filter(full_auths, coauthors == 0)),
    Women = nrow(filter(full_auths, coauthors == 0, gender == "F")),
    Men = nrow(filter(full_auths, coauthors == 0, gender == "M")),
    Unknown = nrow(filter(full_auths, coauthors == 0, is.na(gender)))
  )) %>% 
  mutate(ratio = paste0(round(100 * ratio, 2), "%")) %>%
  rename(Subfield = subfield, "Number of Papers" = "Papers", "All single author" = single, "Percent single" = ratio)

tbl %>%
  knitr::kable(format = "latex",
               booktabs = T,
               align = "lrrrrrr",
               linesep = c(rep("", nrow(tbl) - 2), "\\addlinespace"),
               caption = "Number of papers by subfield and gender, sorted by the overall percentage of single-author papers.") %>%
  column_spec(1, width = "3.5cm") %>%
  column_spec(2:6, width = "1.1cm") %>%
  kable_styling(font_size = 7)
```


```{r solo-props-by-subfield-and-gender, eval=F, echo=F, warning=F, message=F, cache=T, fig.height=6.5, out.width='0.75\\textwidth', fig.cap="Percentage of papers in each subfield that were written by a single author, grouped by the gender of the first author. Triangles demote overall ratio of single-author papers in the subfield irrespective of gender."}
full_auths %>%
  group_by(subfield) %>%
  mutate(N = n(), avg_solo = sum(coauthors == 0) / n_distinct(key)) %>%
  ungroup() %>%
  group_by(key) %>%
  mutate(first_gender = first(gender)) %>%
  ungroup() %>%
  filter(!is.na(first_gender)) %>%
  group_by(subfield, field, avg_solo, first_gender, N) %>%
  summarize(.groups = "keep", pct_solo = sum(coauthors == 0) / n_distinct(key)) %>%
  ggplot(aes(x = fct_reorder(subfield, avg_solo), y = pct_solo, fill = field, color = first_gender)) +
    geom_col(stat= "identity", position = "dodge", size = 1) +
    geom_point(aes(y = avg_solo), color = "black", shape = 2) +
    geom_text(aes(x = fct_reorder(subfield, avg_solo), y = 0.18, label = paste0("N=", fmt(N))), hjust = 1, angle = 0, size = 3, color = "black") +
    scale_color_manual(values = c(cwomen, cmen), labels = c("Women", "Men")) +
    theme_classic() +
    theme(legend.position = "bottom", legend.box = "vertical") +
    guides(
      fill = guide_legend(direction = 'horizontal', title = "Gender"),
      color = guide_legend(direction = 'horizontal', title = "Field")
      ) +
    labs(y = "Percent of papers written by single authors", x = "Subfield") +
    scale_y_continuous(labels = scales::percent) +
    scale_fill_brewer(palette = "Paired") +
    coord_flip()
```

```{r solo-props-by-subfield, eval=F, echo=F, warning=F, message=F, cache=T, fig.height=6.5, out.width='0.75\\textwidth', fig.cap = "Percentage of papers in each subfield that were written by a single author."}
full_auths %>%
  group_by(subfield) %>%
  mutate(N = n(), avg_solo = sum(coauthors == 0) / n_distinct(key)) %>%
  ungroup() %>%
  group_by(key) %>%
  ungroup() %>%
  group_by(subfield, field, avg_solo, N) %>%
  summarize(.groups = "keep", pct_solo = sum(coauthors == 0) / n_distinct(key)) %>%
  ggplot(aes(x = fct_reorder(subfield, avg_solo), y = avg_solo, fill = field)) +
    geom_col(stat= "identity", size = 1) +
    geom_text(aes(x = fct_reorder(subfield, avg_solo), y = 0.13, label = paste0("N=", fmt(N))), hjust = 1, angle = 0, size = 3) +
    theme_classic() +
    theme(legend.position = "bottom", legend.box = "vertical") +
    guides(color = guide_legend(direction = 'horizontal', title = "Field")) +
    labs(y = "Percent of papers written by single authors", x = "Subfield") +
    scale_y_continuous(labels = scales::percent) +
    scale_fill_brewer(palette = "Paired") +
    coord_flip()
```

Another way to look at the same data is from the perspective of papers instead of authors.
As the data in Table \@ref(tab:single-authors) shows, in most CS subfields, fewer than 5% of papers were written by a single author, averaging only `r tbl[nrow(tbl),4]`.
(Contrast this, for example, with Astronomy, Physics, and Biology, where the rates of single-author papers average over 10% [@abt07:future].)

Breaking down the data by gender offers little information, because the numbers of single-author papers per subfield are too small for statistical significance.
In fact, the numbers of single-author papers are so low, as is the number of women authors overall, that their intersection is actually empty for most subfields.
That said, women published relatively fewer single-author papers than men (by percentage) in all but three of the subfields: WWW, Data Science, and Storage.
In all three, the numbers are simply too small to draw any conclusive inferences.

It is also worth noting that in much of the systems field the percentage of single-author papers is extremely low, and is zero in five of those.
This observation may be another indication that the systems field in particular depends on larger collaboration teams for published research.
What is it about this field that requires such collaborations?
We hypothesize that the emphasis on complex implementations and experimental platforms requires larger teams to pull off, which we address in the next research question.

---

## RQ6: Are team sizes larger in more experimental subfields?

The data we collected on coauthorship size and single-authorship shows that authorship norms vary significantly by field, if not by gender. 
The largest coauthorship groups appear in computer systems papers, averaging
`r round(mean(filter(full_auths, field == "Computer Systems")$coauthors + 1), 2)`
coauthors per paper, followed by HCI
(`r round(mean(filter(full_auths, field == "HCI")$coauthors + 1), 2)`),
knowledge systems
(`r round(mean(filter(full_auths, field == "Knowledge Systems")$coauthors + 1), 2)`),
software engineering and programming languages
(`r round(mean(filter(full_auths, field == "SE/languages")$coauthors + 1), 2)`),
AI
(`r round(mean(filter(full_auths, field == "AI")$coauthors + 1), 2)`),
CS education
(`r round(mean(filter(full_auths, field == "CS Education")$coauthors + 1), 2)`),
and finally theory
(`r round(mean(filter(full_auths, field == "Theory")$coauthors + 1), 2)`).

This data do appear to confirm the hypothesis that experimental fields generally require larger teams to design, engineer, implement, and measure research results.
For example, research in computer architecture, the most collaborative of our subfields, often requires large investments in effort (and often, in capital).
This characterization extends to most computer systems subfields of research that occupy the top spots in terms of collaboration sizes.
It appears indeed that the larger effort and resource requirement is associated with larger collaborations, as expressed in mean number of coauthors.

On the opposite end, research in computer theory requires virtually no equipment and is often carried out by individuals, as we have previously observed.
The characteristics of theory research are naturally very similar to those of mathematicians as a whole, so it is perhaps not surprising that the mean number of coauthors we found for theory is nearly identical to the one found for Mathematics [@mihaljevic16:effect].


---

## RQ7: Do authors exhibit gender homphily?

For our last research question, we follow the approach of Wang et al. to estimate whether authors collaborate with coauthors of the same gender at rates higher than expected [@wang21:trends].
For this computation, we look at every pairing of coauthors as one coauthoring event (omitting single-author papers), and ask whether same-gender pairings occur at a higher frequency than we would observe from a random pairing.
A random pairing is expected to follow the same overall statistics for gender distribution, i.e., the expected probability of any (co)author to be a woman should be the same as the overall FAR.

As Wang's study has also found, our data suggests that is not the case for CS, and authors---especially women---are actually more likely to collaborate with coauthors of the same gender.
Overall, the probability of a woman's coauthor to be a woman in our dataset is
`r pct(nrow(filter(all_pairs, gender1 == "F", gender2 == "F")), nrow(filter(all_pairs, gender1 == "F")))`%,
nearly ten percentage points above the overall FAR.
For men, the probability to collaborate with a woman is 
`r pct(nrow(filter(all_pairs, gender1 == "M", gender2 == "F")), nrow(filter(all_pairs, gender1 == "M")))`%,
slightly below the overall FAR.

```{r prob-female-by-subfield, echo=F, warning=F, message=F, cache=T, fig.height=6.5, out.width='0.75\\textwidth', fig.cap="Probability of an author to coauthor with a woman (triangles denote overall probability for subfield, which is similar to FAR but excludes single authors). Women show gender homophily when their probability to coauthor with a woman is higher than the overall probability, and men exhibit homophily when their probability is lower than the overall's."}
pairs_with_field %>%
  group_by(subfield) %>%
  mutate(.groups = "keep", avg_prob = sum(gender2 == "F") / n()) %>%
  ungroup() %>%
  group_by(subfield, avg_prob, gender1) %>%
  summarize(.groups = "keep", Probability = sum(gender2 == "F") / n(), field = first(field), subfield = first(subfield)) %>%
    ggplot(aes(x = fct_reorder(subfield, avg_prob), y = Probability, color = gender1, fill = field)) +
    geom_bar(stat = "identity", position = "dodge", size = 1) +
    geom_point(aes(y = avg_prob), color = "black", shape = 2) +
    xlab("Subfield") +
    ylab("Probability of coauthor being female") +
    theme_classic() +
    theme(legend.position = "bottom", legend.box = "vertical") +
    guides(color = guide_legend(direction = 'horizontal', title = "Gender"),
           fill = guide_legend(direction = 'horizontal', title = "Field")) +
    scale_color_manual(values = c(cwomen, cmen), labels = c("Women", "Men")) +
    scale_fill_brewer(palette = "Paired") +
    coord_flip()
```



We can also break down these probabilities by subfield (\@ref(fig:prob-female-by-subfield)).
As a generalization, most subfields exhibit gender homophily, especially in the two subfields with the highest FAR (CS education and HCI).
A few subfields exhibit gender heterophily, but typically very little.
A curious exception is the subfield of programming languages, where women only have a probability of
`r pct(nrow(filter(pairs_with_field, gender1 == "F", gender2 == "F", subfield == "Programming Languages")), nrow(filter(pairs_with_field, gender1 == "F", subfield == "Programming Languages")))`%
to collaborate with a woman, less than half the overall FAR for the field.
Together with the subfield of software engineering, this field appears show consistent heterophily among its female authors.

All other fields show fairly consistent gender homophily to varying degrees.
For example, in the large field of computer systems, women have a probability of
`r pct(nrow(filter(pairs_with_field, gender1 == "F", gender2 == "F", field == "Computer Systems")), nrow(filter(pairs_with_field, gender1 == "F", field == "Computer Systems")))`%
to collaborate with a woman, above the $\approx{10}\%$ FAR.
In all cases, the more pronounced deviations from the expected probability is for women, suggesting that perhaps collaborating with same-gender authors is more important to women.
Note, however, that since most authors are men and therefore overall FAR is mostly determined by men, we would expect men's deviations from FAR to be smaller than women's.

---


<!-------------------------------------------------------------------------------->
<!-------------------------------------------------------------------------------->

# Discussion {#sec:discussion}

In this section we dive deeper into the data by exploring the relationships between the different measurements and metrics, summarized in Table \@ref(tab:subfield-aggregation).
The first relationship we investigate is between productivity (RQ3) and FAR.
In other words, can the higher observed productivity of men explain why we observe so many more male authors than females?

The answer appears to be "mostly not."
Obviously, the observation that men publish more than women implies that we would find more names of men on papers than we would of women, leading to lower FAR.
When aggregating the data on a subfield basis we do indeed find a moderate negative correlation between a subfield's FAR and the mean productivity of its practitioners
(`r report_test(cor.test(subfield_summary$FAR, subfield_summary$avg_prod))`).
This correlation is even lower when using the fractional paper count for productivity (RQ4), since the slightly larger team sizes for men attenuate some of their productivity advantage
(`r report_test(cor.test(subfield_summary$FAR, subfield_summary$avg_frac))`).

Overall, the relatively modest advantage in overall productivity for men
(`r round(mean(100 * filter(gen_auths, gender == "M")$prod) / mean(filter(gen_auths, gender == "F")$prod) - 100, 2)`% more papers per author) does not directly translate to the nearly 9:1 ratio of male-to-female authorship.
In fact, if we ignore repeated publications altogether and look simply at the ratio of unique women among all unique authors, we still observe a ratio of
`r tmp <- gen_auths %>% group_by(gender) %>% summarize(.groups = "keep", names = n_distinct(name)); pct(filter(tmp, gender=="F")$names, sum(tmp$names))`%
women overall.
While this ratio represents a slight improvement over the non-unique FAR, it is still far from parity, suggesting that higher productivity alone cannot fully explain the gender gap.


Some subfields show no apparent relationship between the FAR and productivity, like storage and machine learning, which have very similar FARs but very dissimilar productivity gaps.
Other subfields exhibit a stronger opposite relationship, like HCI and compilers, with similar productivity metrics but very dissimilar FARs.

```{r subfield-aggregation, echo = F, cache = T}
rounding = 3

tbl <- data.frame(
    Subfield = subfield_summary$subfield,
    FAR = round(subfield_summary$FAR, rounding),
    "Mean productivity" = round(subfield_summary$avg_prod, rounding),
    "Fractional productivity" = round(subfield_summary$avg_frac, rounding),
    "Mean coauthors" = round(subfield_summary$avg_coauthors, rounding),
    "Women's homophily" = round(subfield_summary$whomo, rounding),
    check.names = F
)

tbl$Subfield = recode_factor(
  tbl$Subfield,
  "Artificial Intelligence" = "AI",
  "Theoretical Computer Science" = "Theoretical CS",
  "Computer Architecture" = "Architecture",
  "Computer Science Education" = "CS Education",
  "Computational Linguistics" = "CL",
  "Data Science & Mining" = "DS & Mining",
  "High-Performance Computing" = "HPC",
  "Human-Computer Interaction" = "HCI",
  "Information Retrieval" = "IR",
  "Programming Languages" = "PL",
  "Operating Systems" = "OS",
  "Software Engineering" = "SE"
)

tbl %>%
  arrange(desc(FAR)) %>%
  knitr::kable(format = "latex",
               booktabs = T,
               align = "lrrrrr",
               linesep = "",
               caption = "Comparison of subfields by different gender metrics, ordered by FAR. Metrics include mean productivity (papers per author), ratio of men's productivity to women's, mean total coauthors (with repeats), the ratio between a woman's probability to coauthor with a woman and FAR.") %>%
  column_spec(1, width = "2.0cm") %>%
  column_spec(2:6, width = "1.4cm") %>%
  kable_styling(font_size = 7)
```

A hypothetical relationship between FAR and the typical collaboration size in a subfield (RQ4) can also be easily refuted with counter examples.
Consider the subfields of Algorithms and Architecture.
Although their FAR values are nearly identical, they are on extreme ends of the average team sizes.
The overall correlation between the two metrics is indeed negative, but too close to zero for significance.
(`r report_test(cor.test(subfield_summary$FAR, subfield_summary$avg_coauthors))`).



Last on our list of comparisons is gender homophily (RQ6).
The method we previously used to measure homophily, deviation from the expectation (FAR) produces two measures per field, one for men and one for women.
We will focus on the latter, because the deviation from FAR for men is nearly negligible, because of the high number of men in the data.
We instead look at "women's homophily", defined as the ratio between a subfield's probability for a woman in to coauthor with a woman and its FAR, but still find that is completely uncorrelated with FAR
(`r report_test(cor.test(subfield_summary$FAR, subfield_summary$whomo))`).
This finding is explained by the low statistical probability of a woman (or anyone) to collaborate with a woman.

This high skew also means we cannot use standardized metrics for homophily such as Krackhardt's E-I Index, defined simply as
$EI=\frac{External - Internal}{External + Internal}$
(where $Internal$ represents all the same-gender pairings in our dataset and $External$ all other pairings).
In our data, this metric is strongly correlated with a subfield's FAR
(`r tmp <- pairs_with_field %>% group_by(subfield) %>% summarize(ei_index = first(ei_index)) %>% right_join(subfield_summary); report_test(cor.test(tmp$FAR, tmp$ei_index))`),
to the point of adding no valuable information.
This finding also makes sense: if there are very few women in a field, most coauthor pairings will be internal male-male, all other things being equal.

The upshot of these observations is that homophily measures appear to be much more the result of a skewed FAR than its cause.
In other words, gender homophily appears to have little role in explaining variations in FAR, at least when it deviates significantly from 50% as it does in our dataset.


 * Theoretical CS is an extreme point by almost all metrics, and matches what [@mihaljevic16:effect] found for math.

 * Linear regression / decision tree model predicting subfield FAR from the others. Possibly mixed-effects with field.

Although none of these metrics in isolation is strongly associated with subfield's FAR, it is possible that in combination they can explain a significant part of the variance in the representation of women.
To test this hypothesis, we built a linear regression model using FAR as our response variable and all other metrics as predictors.
<!-- To account for the fact that some characteristics of an entire field are not captured by our choice of metrics, such as their experimental nature (RQ6), we also include the field as a random effect in the model.-->
 
<!-------------------------------------------------------------------------------->
<!-------------------------------------------------------------------------------->

# Conclusions {#sec:conclusion}

CS is a collaborative discipline! Very few single-author papers
So it is important to study collaboration patters as a potential source of explanations for the large gender gap in the field.

Future work: network analyses, such as degree centrality; evolution of patterns over time.
speculate on causality and "whysofew"
 
