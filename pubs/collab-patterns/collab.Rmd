---
title: Gender differences in collaboration patterns in computer science
bibliography: ../sysconf.bib
simplesummary: |
  A Simple summary goes here.
abstract: |
  A single paragraph of about 200 words maximum. For research articles,
  abstracts should give a pertinent overview of the work. We strongly encourage
  authors to use the following style of structured abstracts, but without
  headings: 1) Background: Place the question addressed in a broad context and
  highlight the purpose of the study; 2) Methods: Describe briefly the main
  methods or treatments applied; 3) Results: Summarize the article's main
  findings; and 4) Conclusion: Indicate the main conclusions or interpretations.
  The abstract should be an objective representation of the article, it must not
  contain results which are not presented and substantiated in the main text and
  should not exaggerate the main conclusions.
keywords: |
  keyword 1; keyword 2; keyword 3 (list three to ten pertinent keywords specific
  to the article, yet reasonably common within the subject discipline.).
acknowledgement: |
  All sources of funding of the study should be disclosed. Please clearly
  indicate grants that you have received in support of your research work.
  Clearly state if you received funds for covering the costs to publish in open
  access.
authorcontributions: |
  For research articles with several authors, a short paragraph specifying their
  individual contributions must be provided. The following statements should be
  used ``X.X. and Y.Y. conceive and designed the experiments; X.X. performed the
  experiments; X.X. and Y.Y. analyzed the data; W.W. contributed
  reagents/materials/analysis tools; Y.Y. wrote the paper.'' Authorship must be
  limited to those who have contributed substantially to the work reported.
conflictsofinterest: |
  The authors declare no conflict of interest.
funding: |
  SJREF
institutionalreview: |
  IRB number
informedconsent: |
  Any research article describing a study involving humans should contain this statement. Please add ``Informed consent was obtained from all subjects involved in the study.'' OR ``Patient consent was waived due to REASON (please provide a detailed justification).'' OR ``Not applicable'' for studies not involving humans. You might also choose to exclude this statement if the study did not involve humans.
dataavailability: |
  github, doi, supplemental
output:
  bookdown::pdf_book:
    keep_tex: true
    template: main.tex
    citation_package: natbib
    fig_caption: true
---

```{r code = readLines("../load_data.R"), echo = F, message = F}
```

```{r setup, echo=F, message=F, warning=F, cache=T}
library('rjson')
library('kableExtra')

# This function reads in a .json conference file and for each paper in the conference it extracts the author names, paper id,
# field, and conference id into a data frame. It then normalizes the names using 'normalized_author_name' and moves
# on to the next paper, stacking the new data frame with those that have already been created each time.
# Finally it normalizes the author names and joins with a gender mapping df to get the corresponding genders.

json_to_df <- function(conf_name, gender_mapping) {
  json_fpath <- paste0(toplevel, "data/conf/", conf_name, ".json")
  conf <- rjson::fromJSON(file = json_fpath)
  confname <- conf[[1]]
  field <- conf[['field']]
  subfield <- conf[['subfield']]
  papers <- conf[['papers']]
  submissions <- conf[['submissions']]

  conf_info_df <- data.frame()

  for (i in seq_along(papers)) {
    paper_id <- unlist(papers[[i]][1])
    authors <- as.data.frame(papers[[i]][3]) %>%
      mutate(conf = confname,
             field = field,
             subfield = subfield,
             paper_id = paper_id,
             n_submissions = submissions)

    conf_info_df <- bind_rows(conf_info_df, authors)
  }

  conf_info_df <- conf_info_df %>%
    mutate(authors = map_chr(authors, normalized_author_name)) %>%
    mutate(authors = str_replace(authors, "\\s+", " ")) %>%
    mutate(paper_id = as.factor(paper_id)) %>%
    rename(name = authors)

  conf_info_df %>%
    left_join(gender_mapping, by = "name")
}

######################
# Here we create a vector of the conference names and use the 'map_dfr' function to apply 'json_to_df' to each conference.
nonsys_confs <-
  c("AAAI", "ACL", "CHI", "CVPR", "FSE", "ICML", "ICSE", "MM", "NIPS", "POPL", "SIGCSE", "SIGGRAPH", "SODA", "STOC", "WSDM", "WWW", "ITICSE", "FOCS", "TACAS")

nonsys_authors <- nonsys_confs %>%
  map_dfr(~json_to_df(.x, all_genders)) %>%
  mutate(across(.cols = everything(), na_if, "NA")) %>%
  mutate(across(c(field, subfield, gender), factor))
  

###########
name_combination_creator <- function(df)
{
  authors <- df$name
  if (length(authors) <= 1) {
    return (data.frame(name1 = c(), name2 = c()))
  }

  ret <- as.data.frame(t(combn(authors, 2)))
  names(ret) <- c("name1", "name2")
  ret <- rbind(ret, data.frame(name1 = ret$name2, name2 = ret$name1))
  return(ret)
}

#######
# All-to-all coauthor pairs for non-sys and for sys:
nonsys_collaboration_pairs <- nonsys_authors %>%
  group_by(paper_id) %>%
  group_modify(~name_combination_creator(.x)) %>%
  ungroup() %>%
  left_join(all_genders, by = c("name2" = "name")) %>%
  rename(gender2 = gender) %>%
  left_join(all_genders, by = c("name1" = "name")) %>%
  rename(gender1 = gender) %>%
  dplyr::select(paper_id, name1, gender1, name2, gender2)

sys_collaboration_pairs <- coauthors %>%
  left_join(persons, by = c("name1" = "name", "gs_email1" = "gs_email")) %>%
  rename(gender1 = gender, paper_id = paper) %>%
  left_join(persons, by = c("name2" = "name", "gs_email2" = "gs_email")) %>%
  rename(gender2 = gender) %>%
  dplyr::select(paper_id, name1, gender1, name2, gender2) %>%
  distinct(name1, name2, paper_id, .keep_all = T)

all_pairs <- rbind(nonsys_collaboration_pairs, sys_collaboration_pairs)

#####################
gender_summary_table <- function(data)
{
  data %>%
    summarise(.groups = "keep",
      n_papers = n_distinct(paper_id, conf),
      n_na = sum(is.na(gender)),
      n_male = sum(gender == "M", na.rm = T),
      n_female = sum(gender == "F", na.rm = T),
      prop_female = n_female / (n_female + n_male)
    ) %>%
    arrange(desc(prop_female)) %>%
    knitr::kable()
}

#######

sys_auths <- roles %>% 
  filter(role == "author") %>% 
  left_join(persons, by = c("name" = "name", "gs_email" = "gs_email")) %>% 
  dplyr::select(name, gender, key, as_author) %>% 
  mutate(conf = as.factor(gsub("_\\d\\d\\d$", "", key))) %>% 
  left_join(all_confs, by = c("conf" = "conference")) %>% 
  rename(key = key.x) %>% 
  dplyr::select(name, gender, key, field, subfield, as_author)

nonsys_auths <- nonsys_authors %>% 
  dplyr::select(-conf, -n_submissions) %>% 
  dplyr::select(name, gender, paper_id, field, subfield) %>% 
  rename(key = paper_id) %>% 
  add_count(name) %>% 
  rename(as_author = n)

full_auths <- bind_rows(sys_auths, nonsys_auths) %>%
  group_by(key) %>%
  mutate(coauthors = n())

full_auths$subfield = recode_factor(full_auths$subfield,
                                    "Heterogeneous Computing" = "Computer Architecture",
                                    "Virtualization" = "Operating Systems",
                                    "Energy" = "Computer Architecture",
                                    "Architecture" = "Computer Architecture")

full_auths$field = recode_factor(full_auths$field,
                                 "Systems" = "Computer Systems",
                                 "Computer Science Education" = "CS Education",
                                 "Artificial Intelligence" = "AI",
                                 "Human-Computer Interaction" = "HCI",
                                 "Theory and Algorithms" = "Theory",
                                 "Software Engineering & Languages" = "SE/languages")

gen_auths <- full_auths %>% drop_na(gender)

cwomen <- "#7704FF"
cmen <- "#00C3AA"
cmen <- "gray70"
cwomen <- "gray30"

#######
productivity_diff <- function(sf)
{
  men <- filter(gen_auths, gender == "M", subfield == sf)
  women <- filter(gen_auths, gender == "F", subfield == sf)
  paste0(round(mean(men$as_author) - mean(women$as_author), 2), "; ",
         report_test(t.test(men$as_author, women$as_author)))
}
```

# Introduction

The gender gap in science, technology, engineering and mathematics (STEM), and in particular in computer science (CS), is a well-known and well-studied problem.
It carries significant societal effects, such as inequality in economic opportunities for women and an undersupply of researchers and engineers in the rapidly growing discipline [@nielsen17:opinion; @mattis07:upstream].
The gender gap among researchers is particularly severe: the people who participate in research, publish about it, and have their research acknowledged for its value are predominantly men [@charman17:championing].
Numerous studies estimate that only about 15%--30% of the CS research community are women [@cohoon11:cspapers; @holman18:gender; @national20:science; @way16:gender; @zweben18:taulbee].
Although some recent indications show these numbers could be growing, they remain low, and the rate of growth remains slow [@wang21:trends].

The gender gap is a complex, multifaceted challenge [@avolio20:factors].
Numerous approaches to understand and perhaps address the gender gap have focused on facets such as resource availability, gender stereotypes, child care, structural barriers, gender differences, discrimination, and other factors.
This article focuses on one of these factors: the collaboration patterns of paper coathors across genders and CS fields.

Scientific collaborations are the backbone of a successful career in science [@whittington18:tie].
For example, researchers with more collaborators have been found to publish more articles, in higher impact journals, and accrue more citations more quickly [@lee05:impact].
Consequentlly, many studies investigated whether women and men collaborate at different rates across discplines, and often found significant differences [@bozeman04:scientists; @hunter08:collaborative; @kyvik96:child; @scott90:disadvantage].

In CS, and in particular in its more experimental fields such as computer systems, graphics, and artificial intelligence (AI), collaboration is crucial because the large-scale implementation efforts involved often require teams of researchers with various experience levels.
In this article we focus on gender differences in collaboration patterns across the fields and subfields of CS.

Our study design is descriptive and observational in nature.
We did not start out with any preset hypotheses to validate.
Instead, our goal was to collect and analyze up-to-date, accurate and extensive data on CS authorship and collaboration patterns across genders.
This data and analysis provides baseline statistics for comparison across different time points and scientific disciplines.
But it also provides immediate answers and comparisons to other works that can provide new insights into the current state of collaboration differences across genders and CS fields.
Specifically, in this article we address the following research questions:

 *  **RQ1**: What are the ratios of women and men among CS conference authors?
 
 *  **RQ2**: Do women publish less than men?

 *  **RQ3**: Do women collaborate with fewer people than men?

 *  **RQ4**: Do authors exhibit gender homophily in their choice of coauthrs?

 *  **RQ5**: Do women publish fewer single-author papers?

 *  **RQ6**: Are team sizes (coauthor groups) larger in more experimental subfields?

To bring these questions into historical context, we briefly survey some of the previous work in the area next.

## Related work {-}

There exists a very rich literature on the gender gap in sciences in general, and in computer science research in particular.
For a recent review of this literature, refer to [@avolio20:factors].
Instead, we limit our focus to the relevant literature on collaboration patterns and differences.

For example, a recent study of differences in collaboration patterns across disciplines found that female scientists have a lower probability of repeating previous coauthors than males.
It also found that female faculty have significantly fewer distinct coauthors over their careers than males, but that this difference can be fully accounted for by femalesâ€™ lower publication rate and shorter career lengths [@zeng16:differences].

This productivity gap, which we observed in our dataset as well, has been thoroughly explored in a different study [@symonds06:gender].
In the social sciences, one study has found that women generally publish fewer papers than men, and that two thirds of the single-author papers were written by men [@schucan11:women].
In mathematics, women also publish less than men, especially early in their careers, and leave academia at a higher rate then men [@mihaljevic16:effect].
Women are also underrepresented in the three top-ranked journals and publish fewer single-author papers. In terms of mean number of coauthors, women's statistics are similar to men's.
There is even a gap in recognition, as women are also less likely to receive tenure the more they coauthor [@sarsons17:recognition].




CS researchers in particular tend to collaborate more than researchers in other fields, regardless of gender, and there are no gender-specific differences in how collaborative behavior impacts scientific success [@jadidi18:gender].
This study also found that gender homophily in CS has been increasing over the past few years.

Related, another study of collaboration patterns across sciences found that CS papers average 2.84 coauthors, and electrical engineering papers average 3.04 [@ghiasi15:compliance], similar to what we have found in this study.
It also found that generally in engineering, female-female collaborations accounted for only 7% of all total pairs.
In CS, the percentage is even lower (5%).
Since 1990, there have been even more same-gender (gender homophily) coauthorships than expected [@wang21:trends].
But this property can vary across CS fields, necessitating more nuanced analysis.
For example, in the field of data visualization, women collaborated with subtantially more women than men [@tovanich21:gender].

Corroborating this result for biotech patent networks, women have been found more likely to collaborate with women, and benefit from it, but both genders collaborate with mostly men [@whittington18:tie].
There are also fewer women "stars", which we also found to hold specifically for the subfield of high-performance computing [@frachtenberg21:whpc].

A surprising result came from a survey of 1,714 scientists in 2011, finding that when accounting for various confounding factors, women actually have more collaborators then men [@bozeman11:men].
The paper also reported that regression models that take into account different collaboration strategies are better at predicting a researcher's number of collaborators.

Several studies analyzed the gender gap by aggregating the coauthors of each paper into one "gender".
One study analyzed different aggregations based the proportion of female authors, gender of most senior authors, and single-author papers [@hengel17:publishing].
Looking at author position for aggregation, another study found that there are fewer women in first and last author positions in science overall, as well as in single-author papers [@west13:role].
Other ways to aggregate genders including counting all papers that have at least one female author, and those where at least half the authors are female.


## Organization {-}

The rest of this paper is organized as follows.
In the next section (Sec. \@ref(sec:data)), we describe in detail our data collection methodology, including the manual assigment of genders to authors to avoid the well-known issues of name-based gender inference.
In the results section (Sec. \@ref(sec:results)), we enumerate our findings, organized by research question, and then summarize an answer to each of the questions.
The discussion (Sec. \@ref(sec:discussion)) that follows then elaborates on these answers in an attempt to synthesize insights.
Finally, we conclude in Sec. \@ref(sec:conclusion) and suggest directions for future research.

<!-------------------------------------------------------------------------------->
<!-------------------------------------------------------------------------------->

# Materials and Methods {#sec:data}

To answer our research questions, we needed to collect expansive data on CS publications and their authors.
Such data collection involves many choices, such as which publications to collect and how to assign gender to authors.
The following list enumerates our main data decisions.
Each choice necessarily involves trade-offs, and we attempt to justify our choices by explaining which aspects of the trade-off we prioritized.

The data reflects a snapshot in time, not annual trend, to avoid complexities of gender differences in drop-out rates.

```{r all-confs, echo=F, cache=T}
# this is all nonsys conferences
nonsys_full_table <- nonsys_authors %>%
  group_by(conf) %>%
  mutate(Papers = n_distinct(paper_id, conf), Authors = n_distinct(name, conf, na.rm = T)) %>%
  distinct(conf, .keep_all = T) %>%
  ungroup() %>%
  mutate(Acceptance = round(Papers / n_submissions, 2)) %>%
  mutate(Conference = gsub("_\\d*", "", conf)) %>%
  dplyr::select(Conference, subfield, field, Papers, Authors, Acceptance) %>%
  rename(Field = field, Subfield = subfield)

# this is all other conferences
sys_full_table <- all_confs %>%
  mutate(Conference = gsub("_\\d*", "", conference)) %>%
  rename(Papers = npapers, Authors = authors_num, Field = field, Subfield = subfield) %>%
  mutate(Acceptance = round(acceptance_rate, 2)) %>%
  dplyr::select(Conference, Subfield, Field, Papers, Authors, Acceptance)

full_table <- dplyr::bind_rows(nonsys_full_table, sys_full_table) %>%
  arrange(Subfield, Acceptance)

full_table %>%
  dplyr::select(-c(Field)) %>%
  mutate(Acceptance = ifelse(is.na(Acceptance), "Unknown", Acceptance)) %>%
  knitr::kable(format = "latex",
               booktabs = T,
               align = "llrrr",
               linesep = "",
               caption = "All conferences, ordered by subfield and acceptance rate") %>%
  kable_styling(latex_options = c("hold_position"), font_size = 7)
```

* Conference data instead of journal data.
In CS, original scientific results are typically first published in peer-reviewed conferences [@patterson99:evaluating; @patterson04:health], and then possibly in archival journals, sometimes years later [@vrettas15:conferences]. To increase the coverage and relevance of our dataset, we only looked at conference publications. The complete list of selected conference can be found in Table \@ref(tab:all-confs).

* Choice of conferences.
Our dataset evolved from our previous study of conferences related to one major subfield, computer systems [@frachtenberg20:survey].
The conferences we selected include some of the most prestigious systems conferences (based on indirect measurements such as Google Scholar's metrics), as well as several smaller or less-competitive conferences for contrast.
For this specific study, we decided to expand the analysis to include some of the most influential conferences in most subfields of CS, based on the same measures.
Obviously, not all subfields have equal numbers of participants or conferences, and we had no set quota for either to be included in our dataset.
Instead, we tried to ensure that each subfield is represented by at least a few hundred authors for statistical power.

* Limit data to a single year.
Many fields and researchers shift characteristics over time, complicating collaboration analyses.
To control for these effects, all of the conferences in our dataset are from a single year, 2017.

* Focus on manual gender assignment. Most studies of author gender at scale use automated approaches to assign gender to authors, typically inferred from given names [@huang20:historical; @karimi16:gender].
These statistical approaches can be reasonably accurate for names of Western origin, and especially for male names  [@cohoon11:cspapers; @mattauch20:bibliometric; @santamaria18:comparison].
We opted instead to rely primarily on a manual approach that can overcome the limitations of name-based inference.
Using web lookup, we assigned the gender of
`r fmt(nrow(verified_gender) + nrow(verified_gender_nonsys))`
of the unique researchers for whom we could identify an unambiguous web page with a recognizable gendered pronoun or absent that, a photo.
(For example, many Linkedin profiles may lack a photo, but include a gendered pronoun in the recommendations section.)
For `r fmt(nrow(inferred_gender) + nrow(inferred_gender_nonsys))`
others, we used genderize.io's automated gender designations if it was at least 90% confident about them [@santamaria18:comparison].
The remaining
`r fmt(filter(full_auths, is.na(gender)) %>% pull(name) %>% unique() %>% length())`
persons were assigned "NA" instead of a gender and were excluded from most analyses.
This method provided more gender data and higher accuracy than automated approaches based on forename and country, especially for women [@karimi16:gender; @lariviere13:bibliometrics; @mattauch20:bibliometric; @squazzoni20:noevidence; @wang21:trends].
Consequently, we have very few NA genders because of our manual approach, relative to comparable studies.
We believe that when analyzing coathuroship networks in particular, omitting a large number of connected sub-networks (such as people from Asia) may distort our results.

* Assignment of field and subfield.
We could find no comprehensive definition and delineation of fields and subfields of CS, so we had to come up with our own, which is necessarily subjective (Table \@ref(tab:subfield-mapping)).
Moreover, conferences do not always fall neatly into a single subfield, and some papers may stray from the primary focus of the conference.
We note, however, that in most of our analyses, papers subfields assigned to the same field often exhibited similar characteristics to each other and distinct from other subfields.
This affinity provides evidence that these assignments are not entirely arbitrary.
That said, other researchers may therefore choose different assignments of papers or conferences to subfields and fields.
Since our dataset and code are both open and available, we welcome such reevaluations of the data.

```{r subfield-mapping, echo=F, cache=T}
df <- full_auths %>%
  group_by(subfield) %>%
  summarize(.groups = "keep", Field = first(field)) %>%
  rename(Subfield = subfield)

df$Field = recode_factor(df$Field,
                         "AI" = "Artificial Intelligence (AI)",
                         "HCI" = "Human-Computer Interaction (HCI)",
                         "SE/languages" = "Software Engineering & Programming Languages")

df %>%
  arrange(Field, Subfield) %>%
  knitr::kable(format = "latex",
               booktabs = T,
               align = "ll",
               linesep = "",
               caption = "All CS subfields analyzed, arranged by fields") %>%
  kable_styling()
```


## Limitations {-}

The choices listed above also represent some compromises that limit the generlization or applicability of our analysis.
One such limitation is that the data reflects a snapshot in time to avoid the complexities of gender differences in retention rates.
However, this choice precludes analyses of changes and trends in collaboration patterns over time.

Another limitation is our which conferences to include out of the hundreds or thousands of annual CS conferences.
Our conference choices may not be not representative of all of CS or even a proportional representation of subfields with CS.
The relative metrics we measured comparing different subfields are nevertheless meaningful, but overall metrics should be taken with a grain of salt.
We hope that the large number of authors we included in our dataset does not significantly deviate from a representative sample of the field of CS as a whole.

For this study, the most critical piece of information on these researchers is their \emph{perceived gender}.
Gender is a complex, multifaceted identity, but most bibliometric studies still rely on binary genders---either collected by the journal, or inferred from first name---because that is the only designator available to them [@bhagat18:data; @cohoon11:cspapers; @holman18:gender; @national20:science; @wang21:trends; @way16:gender; @zweben18:taulbee].
In the absence of self-identified gender information for our authors, we also necessarily compromised on using binary gender designations.
We therefore use the gender terms "women" and "men" interchangeably with the sex terms "female" and "male".
The conferences in our dataset did not collect or share specific gender information, so we had to collect this information from other public sources.

This labor-intensive approach does introduce the prospect of human bias and error.
For example, a gender assigned by an outdated biography paragraph with pronouns may no longer agree with the self-identification of the researcher.
To verify the validity of our approach, we compared our manually assigned genders to self-assigned binary genders in a separate survey we conducted among 918 of the authors  [@frachtenberg20:survey].
We found no disagreements for these authors, which suggests that the likelihood of disagreements among the remaining authors is low.
But the main limitation that arises from this manual process of data collection and gender assignment, is that it does not scale well to many more conferences or years.

Finally, the nature of the current analysis is more descriptive than presprictive.
Rather than presenting preconceived hypotheses and testing them with the data, we ask and answer open-ended research questions.
In particular, the scope of this study excludes social network analysis, which is also important to understanding collaboration patterns [@whittington18:tie] and we hope to address in followup work.
The open dataset we provide with this article should enable any interested researcher to perform such analyses as well.

## Statistics {-}

For statistical testing, group means were compared pairwise using Welch's two-sample t-test and group medians using the Wilcoxon Signed Rank Test; differences between distributions of two categorical variables were tested with the $\chi^{2}$ test; and correlations between two numerical variables were evaluated with Pearson's product moment correlation coefficient.
All statistical tests are reported with their p-values.


<!-------------------------------------------------------------------------------->
<!-------------------------------------------------------------------------------->

# Results {#sec:results}

For each research question, we start with descriptive statistics across the entire sample population, and then break the statistics down by field and subfield.

## RQ1 What are the ratios of women and men among CS conference authors?

Before we can look at collaboration patterns, we need to establish a baseline for authorship numbers across genders.
For example, the question of how many women or men an author collaborates with makes little sense without the context of how many women and men are available to collaborate with overall.
The first question we ask, therefore, is what is the female author ratio (FAR) in our dataset.

Summarizing across all `r fmt(nrow(full_auths))` authors and omitting the `r fmt(sum(is.na(full_auths$gender)))` authors for which we could establish no gender, we find a total of `r fmt(sum(gen_auths$gender == "F"))` women, which represents an overall FAR of
`r pct(sum(gen_auths$gender == "F"), nrow(gen_auths))`% across unique authors.
This result is on the low end of previously reported statistics in the range of 15--30% [@cohoon11:cspapers; @holman18:gender; @national20:science; @way16:gender; @zweben18:taulbee].
Keep in mind, however, the differences between those studies and this one, both in data and in methodology.
Our data is modest in size when compared to most other studies, and includes only conferences and only from one year.
Our selection of conferences is by no means exhaustive or objective, and is likely to be overweight in some areas of CS and underweight in others.
However, the smaller sample size allowed us to apply a primarily manual approach to gender assignment, which provides higher accuracy and coverage of researchers.
In contrast, most comparable studies use a gender inference approach based on given names, which can fail for names with unclear or no gender association at all, as are many East Asian names, and tend to misidentify women in particular [@cohoon11:cspapers; @mattauch20:bibliometric; @santamaria18:comparison].
We believe these two differences can explain much of the gap between the FARs observed in our data and in previous datasets.

```{r FAR-by-subfield, echo=F, warning=F, message=F, cache=T, out.width='0.75\\textwidth', fig.cap="Female author ratio by subfield"}
gen_auths %>%
  group_by(subfield) %>%
  summarize(.groups = "keep", FAR = sum(gender == "F") / n(), N = n(), field = first(field), subfield = first(subfield)) %>%
  ggplot(aes(x = fct_reorder(subfield, FAR), y = FAR, fill = field)) +
    geom_bar(stat = "identity") +
    geom_text(aes(x = fct_reorder(subfield, FAR), y = 0.42, label = paste0(subfield, "  N=", fmt(N))), hjust = 1, angle = 0, size = 3) +
    xlab("Subfield") +
    ylab("Female author ratio") +
    labs(fill = "") +
    coord_flip() +
    scale_fill_brewer(palette = "Paired") +
    theme_minimal() +
    theme(legend.position = "bottom",
#          legend.justification = c(0, 0),
          axis.text.y = element_blank(),
          #element_text(angle = 90, hjust = 1, vjust = -0.00001),
          legend.box = "vertical",
          legend.margin = margin())
```

Looking at FAR for each field and subfield (Fig. \@ref(fig:FAR-by-subfield)), we find large differences across CS.
The highest FAR was exhibited in CS education conferences
(`r pct(nrow(filter(gen_auths, gender == "F", subfield == "Computer Science Education")), nrow(filter(gen_auths, subfield == "Computer Science Education")))`%)
and the lowest in theoretical CS
(`r pct(nrow(filter(gen_auths, gender == "F", subfield == "Theoretical Computer Science")), nrow(filter(gen_auths, subfield == "Theoretical Computer Science")))`%).
Most conferences in the field of computer systems hovered around 10% FAR while the entire field AI averaged a little higer at
(`r pct(nrow(filter(gen_auths, gender == "F", field == "AI")), nrow(filter(gen_auths, field == "AI")))`%).



---

## RQ2: Do women publish less than men?

Many papers across disciplines discuss the existence and potential reasons for a productivity gap, that is, the observation that men generally publish more scholarly articles than women.
Here, we continue our exploration of the data by looking at the productivity rates across genders and subfields of CS.


```{r productivity-dist, echo=F, warning=F, message=F, cache=T, out.width='0.75\\textwidth', fig.cap="Distribution of number of distinct papers per author"}
gen_auths %>%
  ggplot(aes(x = as_author, fill = gender)) +
    geom_histogram(position = "dodge", binwidth = 1) +
    scale_fill_manual(values = c(cwomen, cmen), labels = c("Women", "Men")) +
    theme_classic() +
    theme(legend.position = "bottom") +
    xlab("Papers in dataset") +
    ylab("Total authors")
```

Fig. \@ref(fig:productivity-dist) shows the overall distributions of paper productivity in CS across genders.
Aside from the now-obvious observation that men far outnumber women authors overall, we can also observe a longer tail for the men's distribution overall.
The interpretation is that the most prolific authors are especially skewed male.
On the opposite tail, we find that
`r pct(nrow(filter(gen_auths, gender == "F", as_author == 1)), nrow(filter(gen_auths, gender == "F")))`%
of female authors published only one paper in our dataset, compared to
`r pct(nrow(filter(gen_auths, gender == "M", as_author == 1)), nrow(filter(gen_auths, gender == "M")))`%
of men.

Overall, men average
`r round(mean(filter(gen_auths, gender == "M")$as_author), 2)`
papers per author, compared to women's
`r round(mean(filter(gen_auths, gender == "F")$as_author), 2)`
(`r report_test(t.test(filter(gen_auths, gender == "F")$as_author, filter(gen_auths, gender == "M")$as_author))`).
Looking at medians---to attempt to attenuate the large effect of the long tail on means---does not help much.
Both medians are 1; but a Wilcoxon signed rank test still shows a significant difference
(`r report_test(wilcox.test(filter(gen_auths, gender == "F")$as_author, filter(gen_auths, gender == "M")$as_author))`).


```{r productivity-by-subfield, echo=F, warning=F, message=F, cache=T, fig.height=8, out.width='0.75\\textwidth', fig.cap="Distribution of number of distinct papers per author by gender, field, and subfield. Triangles denote means and veritcal notches denote medians. Dots denote outlier points outside the 5--95\\% range."}
gen_auths %>%
  group_by(subfield) %>%
  mutate(avg_prod = mean(as_author), N=n()) %>%
  ungroup() %>%
  ggplot(aes(x = fct_reorder(subfield, avg_prod), y = as_author, fill = gender, color = field)) +
    geom_boxplot(lwd = 0.5) +
    geom_point(aes(y = avg_prod), color = "black", shape = 2) +
#    geom_text(aes(x = fct_reorder(subfield, avg_prod), y = 21, label = paste0("N=", N)), hjust = 1.1) +
    xlab("Subfield") +
    ylab("Paper count per author") +
    theme_classic() +
    theme(legend.position = "bottom", legend.box = "vertical") +
    guides(fill = guide_legend(direction = 'horizontal', title = "Gender"),
           color = guide_legend(direction = 'horizontal', title = "Field")) +
    scale_fill_manual(values = c(cwomen, cmen), labels = c("Women", "Men")) +
    scale_color_brewer(palette = "Paired") +
    coord_flip()
```



Fig. \@ref(fig:productivity-by-subfield) shows the breakdown of productivity distribution by gender, field, and subfield.
The field of AI and its subfields show the highest average productivity (and highest outliers, for men), while software engineering, programming languages, and CS education exhibit the lowest average papers per author.
In terms of gender, the largest differences in productivity exhibit in the subfield of theoretical CS (difference in means: `r productivity_diff("Theoretical Computer Science")`), followed by machine learning (`r productivity_diff("Machine Learning")`), benchmarking (`r productivity_diff("Benchmarking")`), HPC (`r productivity_diff("High-Performance Computing")`), security (`r productivity_diff("Security")`), and AI (`r productivity_diff("Artificial Intelligence")`).
A few subfields show a small productivity advantage for women, such as programming languages (`r productivity_diff("Programming Languages")`), but none are statistically significant.


---


## RQ3: Do women collaborate with fewer people than men?

This question could be addressed by two distinct measures: the mean number of coauthors per paper and the size of the total network size for each author.


```{r coauthors-by-subfield, echo=F, warning=F, message=F, cache=T, fig.height=6.5, out.width='0.75\\textwidth', fig.cap="Mean number of coauthors by gender and subfield (triangles denote overall mean for subfield)."}
gen_auths %>%
  group_by(subfield) %>%
  mutate(avg_co = mean(coauthors)) %>%
  ungroup() %>%
  group_by(subfield, avg_co, gender) %>%
  summarize(.groups = "keep", Coauthors = mean(coauthors), field = first(field), subfield = first(subfield)) %>%
    ggplot(aes(x = fct_reorder(subfield, avg_co), y = Coauthors, color = gender, fill = field)) +
    geom_bar(stat = "identity", position = "dodge", size = 1) +
    geom_point(aes(y = avg_co), color = "black", shape = 2) +
    xlab("Subfield") +
    ylab("Coauthor count per author") +
    theme_classic() +
    theme(legend.position = "bottom", legend.box = "vertical") +
    guides(color = guide_legend(direction = 'horizontal', title = "Gender"),
           fill = guide_legend(direction = 'horizontal', title = "Field")) +
    scale_color_manual(values = c(cwomen, cmen), labels = c("Women", "Men")) +
    scale_fill_brewer(palette = "Paired") +
    coord_flip()
```

Women in our dataset average
<!--excludes solo authors: `r coauthor_count <- all_pairs %>% group_by(paper_id, name1, gender1) %>% summarize(.groups = "keep", n = n()); round(mean(filter(coauthor_count, gender1 == "F")$n), 2)` -->
`r round(mean(filter(gen_auths, gender == "F")$coauthors) - 1, 2)`
coauthors, while men average
`r round(mean(filter(gen_auths, gender == "M")$coauthors) - 1, 2)`
(`r report_test(t.test(filter(gen_auths, gender == "F")$coauthors, filter(gen_auths, gender == "M")$coauthors))`).
This metric appears to show no significant differences in the aggregate.
Breaking it down by field (Figure \@ref(fig:coauthors-by-subfield)) shows that the gender differences remain minimal almost throughout.
The largest difference appear in the subfields of computer architecture
(`r report_test(t.test(filter(gen_auths, subfield == "Computer Architecture", gender == "F")$coauthors, filter(gen_auths, subfield == "Computer Architecture", gender == "M")$coauthors))`)
and operating systems
(`r report_test(t.test(filter(gen_auths, subfield == "Operating systems", gender == "F")$coauthors, filter(gen_auths, subfield == "Operating Systems", gender == "M")$coauthors))`).
In general, the field of computer systems stands out with a an average gender gap of
`r round(mean(filter(gen_auths, field == "Computer Systems", gender == "M")$coauthors) -  mean(filter(gen_auths, field == "Computer Systems", gender == "F")$coauthors), 2)`
fewer coauthors for women than for men
(`r report_test(t.test(filter(gen_auths, field == "Computer Systems", gender == "F")$coauthors, filter(gen_auths, field == "Computer Systems", gender == "M")$coauthors))`).


The second measure is how many distinct authors each person collaborates with across all of their papers---in other words, the size of the network of all a person's collaborators.
In our dataset, women average
`r cohorts <- all_pairs %>% group_by(name1, gender1) %>% summarize(.groups = "keep", cohort = n_distinct(name2, gender2)); round(mean(filter(cohorts, gender1 == "F")$cohort), 2)`
total cohort size, while men average
`r round(mean(filter(cohorts, gender1 == "M")$cohort), 2)`
(`r report_test(t.test(filter(cohorts, gender1 == "F")$cohort, filter(cohorts, gender1 == "M")$cohort))`).
This measure also shows no significant gender differences in the aggregate.
Unfortunately, it cannot be neatly broken down by fields, because coauthor networks often include authors that span more than one field.

Overall, men exhibit slightly higher collaboration metrics than women (more coauthors per paper and more coauthors overall), but not signficantly so.

---


## RQ4: Do authors exhibit gender homphily?

We follow the same approach of Wang et al. to estimate whether authors collaborate with coauthrs of the same gender at rates higher than expected [@wang21:trends].
For this computation, we look at every pairing of coauthors as one coauthoring event (omitting single-author papers), and ask whether same-gender pairings occur at a higher frequency than we would observe from a random pairing.
A random pairing is expected to follow the same overall statistics for gender distribution, i.e., the expected probability of any (co)author to be a women should be the same as the overall FAR.

As Wang's study has also found, our data suggests that is not the case for CS, and authors---especially women---are actually more likely to collaborate with coauthors of the same gender.
Overall, the probability of a woman's coauthor to be a woman in our dataset is
`r pct(nrow(filter(all_pairs, gender1 == "F", gender2 == "F")), nrow(filter(all_pairs, gender1 == "F")))`%,
nearly ten percentage points above the overall FAR.
For men, the probabily to collaborate with a woman is 
`r pct(nrow(filter(all_pairs, gender1 == "M", gender2 == "F")), nrow(filter(all_pairs, gender1 == "M")))`%,
slightly below the overall FAR.

```{r prob-female-by-subfield, echo=F, warning=F, message=F, cache=T, fig.height=6.5, out.width='0.75\\textwidth', fig.cap="Probability of an author to coauthor with a woman (triangles denote overall probability for subfield, which is similar to FAR but excludes single authors). Women show gender homophily when their probability to coauthor with a woman is higher than the overall probability, and men exhibit homophily when their probability is lower than the overall's."}
pairs_with_field <- full_auths %>%    # Add field and subfield to all_pairs
  mutate(paper_id = key) %>%
  group_by(paper_id) %>%
  summarize(.groups = "keep", field = first(field), subfield = first(subfield)) %>%
  right_join(all_pairs) %>%
  drop_na(gender1) %>%
  drop_na(gender2)

pairs_with_field %>%
  group_by(subfield) %>%
  mutate(.groups = "keep", avg_prob = sum(gender2 == "F") / n()) %>%
  ungroup() %>%
  group_by(subfield, avg_prob, gender1) %>%
  summarize(.groups = "keep", Probability = sum(gender2 == "F") / n(), field = first(field), subfield = first(subfield)) %>%
    ggplot(aes(x = fct_reorder(subfield, avg_prob), y = Probability, color = gender1, fill = field)) +
    geom_bar(stat = "identity", position = "dodge", size = 1) +
    geom_point(aes(y = avg_prob), color = "black", shape = 2) +
    xlab("Subfield") +
    ylab("Probability of coauthor being female") +
    theme_classic() +
    theme(legend.position = "bottom", legend.box = "vertical") +
    guides(color = guide_legend(direction = 'horizontal', title = "Gender"),
           fill = guide_legend(direction = 'horizontal', title = "Field")) +
    scale_color_manual(values = c(cwomen, cmen), labels = c("Women", "Men")) +
    scale_fill_brewer(palette = "Paired") +
    coord_flip()
```



We can also break down these probabilities by subfield (\@ref(fig:prob-female-by-subfield)).
As a generalization, most subfields exhibit gender homophily, especially in the two subfields with the highest FAR (CS education and HCI).
A few subfields exhibit gender heterophily, but typically very little.
A curious exception is the subfield of programming languages, where women only have a probability of
`r pct(nrow(filter(pairs_with_field, gender1 == "F", gender2 == "F", subfield == "Programming Languages")), nrow(filter(pairs_with_field, gender1 == "F", subfield == "Programming Languages")))`%
to collaborate with a woman, less than half the overall FAR for the field.
Together with the subfield of software engineering, this field appears show consistent heterophily among its female authors.

All other fields show fairly consistent gender homomphily to varying degrees.
For example, in the large field of computer systems, women have a probability of
`r pct(nrow(filter(pairs_with_field, gender1 == "F", gender2 == "F", field == "Computer Systems")), nrow(filter(pairs_with_field, gender1 == "F", field == "Computer Systems")))`%
to collaborate with a woman, above the ~10% FAR.
In all cases, the more pronounced deviations from the expected probabily is for women, suggesting that perhaps collaborating with same-gender authors is more important to women.
Note, however, that since most authors are men and therefore overall FAR is mostly determined by men, we would expect men's deviations from FAR to be smaller than women's.

---

## RQ5: Do women publish fewer single-author papers?

Next we'll look at all of the solo-authored papers in our data set and compute the proportion of those that are male and female.

```{r solo-props-by-gender, echo=F, warning=F, message=F, cache=T}

prop_solo_table <- gen_auths %>% 
  add_count(key) %>% 
  filter(n == 1) %>% 
  group_by(gender) %>% 
  summarise(n = n()) %>% 
  mutate(prop = round(n/sum(n), 3)) 

total_solo <- prop_solo_table$n[1] + prop_solo_table$n[2]

prop_solo_table %>% 
  knitr::kable(format = "latex",
               booktabs = T,
               align = "llrrr",
               linesep = "") 

```




```{r, echo = F, warning=F, message=F, cache=T}
solo_prop_test <- prop.test(x= c(prop_solo_table$n[1], prop_solo_table$n[2]), n = c(total_solo, total_solo))
```

We find that `r prop_solo_table$prop[1]*100`% of all solo authors in our data set are Female while `r prop_solo_table$prop[2]*100`% of them are Male ($\chi=$ `r round(solo_prop_test$statistic, 3)`, $p <$ `r solo_prop_test$p.value`). Notably this value is lower than the FAR we found of `r pct(sum(gen_auths$gender == "F"), nrow(gen_auths))`%.

Next we'll investigate what percentage of papers that men/women write are solo authored.

```{r solo-props-by-subfield, echo = F, warning=F, message=F, cache=T, fig.height = 6.5,out.width='0.75\\textwidth', fig.cap = "For each gender within each subfield we divided the number solo authorships of that gender by the total number of author contributions for that gender. So the bar at the top of this plot can be interpreted as saying that in Computer Science Education, around 5.5\\% of male contributions are solo authorships."}
solo_by_subfield <- gen_auths %>% 
  add_count(key) %>% 
  filter(n == 1) %>% 
  group_by(gender, subfield, .drop = F) %>% 
  summarise(n = n())

field_subfield <- gen_auths %>% 
  distinct(field, subfield)

prop_by_subfield <- gen_auths %>%
  group_by(gender, subfield, .drop = F) %>%
  distinct(name, .keep_all = T) %>%
  summarise(total = sum(as_author)) %>%
  ungroup() %>% 
  left_join(solo_by_subfield, by = c("subfield", "gender")) %>% 
  mutate(prop = n/total) %>% 
  left_join(field_subfield, by = "subfield") %>% 
  group_by(subfield) %>% 
  mutate(avg_solo = mean(prop, na.rm = T)) %>% 
  ungroup() %>% 
  mutate(subfield = fct_reorder(subfield, avg_solo))


prop_by_subfield  %>% 
  ggplot(aes(x = subfield, y = prop, fill = field, color = gender)) +
  geom_col(stat= "identity", position = "dodge", size = 1) +
  geom_point(aes(y = avg_solo), color = "black", shape = 2) +
  scale_color_manual(values = c(cwomen, cmen), labels = c("Women", "Men")) +
  theme_classic() +
  theme(legend.position = "bottom", legend.box = "vertical") +
  guides(
    fill = guide_legend(direction = 'horizontal', title = "Gender"),
    color = guide_legend(direction = 'horizontal', title = "Field")
    ) +
  labs(y = "Percent of Authorships that are Solo", x = "Subfield") +
  scale_y_continuous(labels = scales::percent) +
  scale_fill_brewer(palette = "Paired") +
  coord_flip()
```


Fig. \@ref(fig:solo-props-by-subfield) shows that in subfields with a lower percentage of solo authorships (below `r round(pull(select(distinct(filter(prop_by_subfield, subfield == "Concurrency"), subfield, .keep_all =T), avg_solo))*100, 3)`%), male solo authorships account for a larger percent of male authorships than female solo authorships do of female authorships. But when we look above `r round(pull(select(distinct(filter(prop_by_subfield, subfield == "Concurrency"), subfield, .keep_all =T), avg_solo))*100, 3)`% we see more variety in which gender is made up of more solo authorships. Notably, there are a few subfields in which solo authorships account for more of total authorships for Female authors than they do for Male authors. These are World-Wide-Web, Data Science, Storage, Multimedia, and Graphics.




---

## RQ6: Are team sizes larger in more experimental subfields?

The data we collected on coauthorship (Fig. \@ref(fig:coauthorship-by-subfield))
shows that authorship norms vary significantly by field, if not by gender. 
The largest coauthorship groups appear in computer systems papers, averaging
`r round(mean(filter(full_auths, field == "Computer Systems")$coauthors), 2)`
coauthors per paper, followed by HCI
(`r round(mean(filter(full_auths, field == "HCI")$coauthors), 2)`),
knowledge systems
(`r round(mean(filter(full_auths, field == "Knowledge Systems")$coauthors), 2)`),
software engineering and programming languages
(`r round(mean(filter(full_auths, field == "SE/languages")$coauthors), 2)`),
AI
(`r round(mean(filter(full_auths, field == "AI")$coauthors), 2)`),
CS education
(`r round(mean(filter(full_auths, field == "CS Education")$coauthors), 2)`),
and finally theory
(`r round(mean(filter(full_auths, field == "Theory")$coauthors), 2)`).

This data do appear to confirm the hypothesis that experimental fields generally require larger teams to design, engineer, implement, and measure research results.
For example, research in computer architecture, the most collaborative of our subfields, often requires large investments in effort (and often, in capital).
This characterization extends to most computer systems subfields of research that occupy the top spots in terms of collaboration sizes.
It appears indeed that the larger effort and resource requirement is associated with larger collaborations, as expressed in mean number of coauthors.

On the opposite end, research in computer theory requires virtually no equipment and is often carried out by individuals, as we have previously observed.
The characteristics of theory research are naturally very similar to those of mathematicians as a whole, so it is perhaps not surprising that the mean number of coauthors we found for theory is nearly identical to the one found for mathematicians [@mihaljevic16:effect].


---

<!-------------------------------------------------------------------------------->
<!-------------------------------------------------------------------------------->

# Discussion {#sec:discussion}

Correlate all variables:

 * Do normalized productivity as well: divided by the number of coauthors per paper, so each author gets a fraction.

 * Relationship between anything and FAR, speculate on causality and "whysofew"
 
 * Theoretical CS is an extreme point by almost all metrics, and matches what [@mihaljevic16:effect] found for math.

<!-------------------------------------------------------------------------------->
<!-------------------------------------------------------------------------------->

# Conclusions {#sec:conclusion}

Future work: network analyses, such as degree centraility; evolution of patterns over time.
